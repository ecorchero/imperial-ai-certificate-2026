{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "UtiBKO4TnIQr",
   "metadata": {
    "id": "UtiBKO4TnIQr"
   },
   "source": [
    "# Self-study try-it activity 12.1: Analysing the effects of hyperparameters on surrogate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14053b44",
   "metadata": {
    "id": "14053b44"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Predicted variances smaller than 0. Setting those variances to 0.\")\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,RationalQuadratic, Matern\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47d66a",
   "metadata": {
    "id": "0d47d66a"
   },
   "source": [
    "To run this notebook, you’ll need scikit-learn version 1.0 or above. Use the cell below to check your current version. If it’s lower than 1.0, install the correct version before continuing by running the following command in your terminal:\n",
    "\n",
    "`conda install scikit-learn=1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420ed41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b420ed41",
    "outputId": "aa4c1785-bb8b-4118-9911-ebfd971bb5a5"
   },
   "outputs": [],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LcZDnwornduh",
   "metadata": {
    "id": "LcZDnwornduh"
   },
   "source": [
    "# Gaussian process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3739d9",
   "metadata": {
    "id": "8a3739d9"
   },
   "source": [
    "First, create the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JdnR6iufof99",
   "metadata": {
    "id": "JdnR6iufof99"
   },
   "outputs": [],
   "source": [
    "np.random.seed(234) #Do not change the random seed\n",
    "x = np.random.uniform(0, 10, (10, 1))\n",
    "\n",
    "def true_function(x):\n",
    "    return -(1.4 - 3.0 * x) * np.sin(x)\n",
    "\n",
    "y = true_function(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6-E7WhB6rbb9",
   "metadata": {
    "id": "6-E7WhB6rbb9"
   },
   "outputs": [],
   "source": [
    "y = y.ravel()  #Convert to 1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EPWPggn3rdqA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "id": "EPWPggn3rdqA",
    "outputId": "a9d6ddf4-e690-4570-b142-0a4d60cb2bb3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "gpr.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cqlTtiwZsdCa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "cqlTtiwZsdCa",
    "outputId": "732bd850-2bec-432f-d51b-8979f9f54cf6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create test points\n",
    "x_test = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_pred, std = gpr.predict(x_test, return_std=True)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_test, true_function(x_test), 'r:', label='True function')\n",
    "plt.scatter(x, y, c='k', label='Observations')\n",
    "plt.plot(x_test, y_pred, 'b-', label='Mean prediction')\n",
    "plt.fill_between(x_test.ravel(),\n",
    "                 y_pred - 1.96 * std,\n",
    "                 y_pred + 1.96 * std,\n",
    "                 alpha=0.2, color='blue', label='95% confidence interval')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Gaussian Process Regression with Your Dataset using RBF Kernel')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YNmDwKtsBgn0",
   "metadata": {
    "id": "YNmDwKtsBgn0"
   },
   "source": [
    "## Answer the following questions\n",
    "\n",
    "- Change the `length_scale` and observe the changes in the plot.\n",
    "\n",
    "- Change the `kernel` to `Matern` and `RationalQuadratic` and observe the changes in the plot.\n",
    "\n",
    "- Change the confidence intervals as follows and observe the plots:\n",
    "\n",
    "  a. 68% confidence interval\n",
    "\n",
    "  b. 90% confidence interval\n",
    "\n",
    "  c. 99% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MknW3JOPJHcZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "id": "MknW3JOPJHcZ",
    "outputId": "5ccbfabf-a0d5-4560-def3-df9a20fd9abd"
   },
   "outputs": [],
   "source": [
    "kernel = 1.0 * Matern(length_scale=2.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "gpr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n4EgP8UpJTym",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "n4EgP8UpJTym",
    "outputId": "33235d46-be39-471e-a066-dede26258ca3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create test points\n",
    "x_test = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_pred, std = gpr.predict(x_test, return_std=True)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_test, true_function(x_test), 'r:', label='True function')\n",
    "plt.scatter(x, y, c='k', label='Observations')\n",
    "plt.plot(x_test, y_pred, 'b-', label='Mean prediction')\n",
    "plt.fill_between(x_test.ravel(),\n",
    "                 y_pred - 1.0 * std,\n",
    "                 y_pred + 1.0 * std,\n",
    "                 alpha=0.2, color='blue', label='68% confidence interval')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Gaussian Process Regression with Your Dataset using Matern kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y6gZ8k3AJqa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Y6gZ8k3AJqa4",
    "outputId": "cb8ee43c-e9c7-46a9-d5bb-a346f0e4e453"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create test points\n",
    "x_test = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_pred, std = gpr.predict(x_test, return_std=True)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_test, true_function(x_test), 'r:', label='True function')\n",
    "plt.scatter(x, y, c='k', label='Observations')\n",
    "plt.plot(x_test, y_pred, 'b-', label='Mean prediction')\n",
    "plt.fill_between(x_test.ravel(),\n",
    "                 y_pred - 2.576 * std,\n",
    "                 y_pred + 2.576 * std,\n",
    "                 alpha=0.2, color='blue', label='99% confidence interval')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Gaussian Process Regression with Your Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4207ae5",
   "metadata": {
    "id": "d4207ae5"
   },
   "source": [
    "## Regression tree parameters\n",
    "\n",
    "Explore how model parameters can affect the quality of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa0197",
   "metadata": {
    "id": "3cfa0197"
   },
   "source": [
    "## Follow these steps:\n",
    "\n",
    "- Experiment with the hyperparameters of the regression trees below to build both the best and worst models you can.\n",
    "\n",
    "- Use `help(DecisionTreeRegressor)` to explore the available hyperparameter options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61215d",
   "metadata": {
    "id": "ee61215d"
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(0, 10, 100).reshape(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZOmIlrbtit8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOmIlrbtit8d",
    "outputId": "6a8c2202-350c-440e-877d-62e3a10f3cd4"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Over-constrained \"worst\" tree → trivial splits\n",
    "clf_worst = DecisionTreeRegressor(criterion=\"squared_error\",\n",
    "                            splitter='random',\n",
    "                            max_depth=3,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=3,\n",
    "                            min_weight_fraction_leaf=0.2,\n",
    "                            max_features=1,\n",
    "                            max_leaf_nodes=2,\n",
    "                            min_impurity_decrease=1.0)\n",
    "\n",
    "print(clf_worst.criterion)\n",
    "\n",
    "clf_worst.fit(x, y)\n",
    "\n",
    "clf_best = DecisionTreeRegressor(criterion='absolute_error',\n",
    "                            splitter='best',\n",
    "                            max_depth=3,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=3,\n",
    "                            #min_weight_fraction_leaf=0.2,\n",
    "                            max_features=1,\n",
    "                            max_leaf_nodes=2,\n",
    "                            #min_impurity_decrease=1.0\n",
    "                                 )\n",
    "\n",
    "clf_best.fit(x, y)\n",
    "\n",
    "y_test_worst = clf_worst.predict(x_test)\n",
    "y_test_best = clf_best.predict(x_test)\n",
    "y_true = true_function(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111289e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "3111289e",
    "outputId": "f5f9445f-55b2-4466-c795-4a58fe58b52b"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Plot shows: true function (black), best-fit tree (blue), worst-fit tree (orange).\n",
    "# Highlights underfitting vs. closer fit to ground truth.\n",
    "plt.scatter(x, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(x_test, y_test_worst,  linewidth=2, label='worst')\n",
    "plt.plot(x_test, y_test_best, linewidth=2, label='best')\n",
    "plt.plot(x_test, y_true, color='k', linestyle=\":\", alpha=0.7, label='true')\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
