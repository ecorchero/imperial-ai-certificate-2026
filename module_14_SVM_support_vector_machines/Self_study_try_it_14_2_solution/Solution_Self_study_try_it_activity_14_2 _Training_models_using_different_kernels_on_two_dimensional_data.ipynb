{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbe21ab-c9b5-4f88-81b5-928b72768ecd",
   "metadata": {},
   "source": [
    "# Self-study try-it activity 14.2: Training models using different kernels on two-dimensional data\n",
    "\n",
    "Training SVM models with different kernels is necessary because each kernel enables the SVM to capture different types of relationships in the data – linear kernels are used for linearly separable data, and non-linear kernels (such as RBF or polynomial) are used for more complex patterns. Testing multiple kernels helps find the one that best fits the underlying structure of the two-dimensional data, improving classification accuracy.\n",
    "\n",
    "In this notebook, the data is trained on different kernels, and the best-performing model is selected based on performance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd057e",
   "metadata": {},
   "outputs": [],
   "source": [
     "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "#Use the following to plot SVMs\n",
    "from mlxtend.plotting import plot_decision_regions #On terminal, install pip.install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301fd9d0",
   "metadata": {},
   "source": [
    "#### Task 1: SVM-based classifier on a non-separable data set\n",
    "**Load the two-dimensional data `Case3rings/X.npy` that has 150 rows and two columns and the corresponding target `Case3rings/y.np.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/Case3rings/X.npy')\n",
    "y = np.load('data/Case3rings/y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c1b9b",
   "metadata": {},
   "source": [
    "**Plot the two-dimensional points and colour them so that points with the same class have the same colour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "color = np.concatenate((np.repeat(\"blue\", n), np.repeat(\"red\",n/2)), axis=0)\n",
    "plt.scatter(X[:,0], X[:,1], c = color, alpha= .5)\n",
    "plt.xlabel(\"$x_1$\", size = 15)\n",
    "plt.ylabel(\"$x_2$\", size = 15)\n",
    "plt.title(\"A clustered class in a ring class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee066f",
   "metadata": {},
   "source": [
    "**Does a linear SVM-based classifier (SVC) sound like a good idea? First, discuss your opinion, then demonstrate it by training, showing the confusion matrix and plotting the boundary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f812ed",
   "metadata": {},
   "source": [
    "- Answer: Linear SVM yields a single straight boundary; concentric rings are not linearly separable, so the model collapses to the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812beb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'linear')\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot(); #You see that this model never predicts -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings(): #Otherwise the package might complain there is no \"boundary\" as we classify all as '1'\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "    ax=plt.gca();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e2d17",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "**In the linear SVC case above, why did your model end up classifying every instance with the same prediction?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94210d",
   "metadata": {},
   "source": [
    "## Answer: \n",
    "A linear SVM kernel can only create a straight-line decision boundary, which cannot separate non-linear data such as two concentric rings. As a result, the model fails to distinguish between the rings and often assigns all instances to the same class, leading to poor accuracy and trivial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2588f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y.ravel()).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a0202",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "**Try a radial kernel instead (with default parameters) and then report the performance and plot the decision boundary.**\n",
    "\n",
    "Notes: \n",
    "- To change the kernel, try, e.g. `kernel = 'rbf.'`\n",
    "- To change the cost, try, e.g. `C = 10.` \n",
    "- To change the scale parameter of the RBF, try, e.g. `gamma = 4.`\n",
    "- See more options in the [official documentation.](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c61a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'rbf')\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c9b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "ax=plt.gca();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e749d45",
   "metadata": {},
   "source": [
    "**Try a radial kernel (or RBF) with gamma = 10.` Interpret the decision boundary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'rbf', gamma = 10)\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "ax=plt.gca();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e46d4b",
   "metadata": {},
   "source": [
    "## Answer: \n",
    "You can see that the shape of the RBF looks less like a circle and starts to obtain 'tentacles'. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e47a3",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "**Apply the same steps for a polynomial kernel with degree 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'poly', degree = 3)\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7286179",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(): #Otherwise the package might complain there is no \"boundary\" as we classify all as '1'\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "    ax=plt.gca();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a21b8f6",
   "metadata": {},
   "source": [
    "**Now try a polynomial Kernel with degree 8 and cost 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c6b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'poly', degree = 8, C = 1)\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(): #Otherwise the package might complain there is no \"boundary\" as we classify all as '1'\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "    ax=plt.gca();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a879449",
   "metadata": {},
   "source": [
    "**Change the cost in the above case to 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'poly', degree = 8, C = 10)\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c86203",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(): #Otherwise the package might complain there is no \"boundary\" as we classify all as '1'\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "    ax=plt.gca();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16022195",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "- As you may have realized, the selection of a Kernel is not straightforward.\n",
    "- The best-performing kernels in this example are the polynomial with degree 8 and cost 10 and the RBF with gamma 10.\n",
    "- Even if you correctly guess the RBF with gamma 10 but use a different cost, your results may get significantly worse. \n",
    "\n",
    "## Question 4:\n",
    "To illustrate the final point, do the following:\n",
    "- Run a radial kernel SVM with gamma 10 but use a cost 0.3.\n",
    "- Run a sigmoid kernel and analyse the outputs of both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1daf19b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'rbf', gamma = 10, C = 0.3)\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(): #Otherwise the package might complain there is no \"boundary\" as we classify all as '1'\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "    ax=plt.gca();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6dcf98",
   "metadata": {},
   "source": [
    "**Now, use a sigmoid kernel, display the confusion matrix and plot the decision boundary. Does the sigmoid kernel look like a good match here?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85288114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'sigmoid')\n",
    "clf.fit(X, y);\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=np.unique(y))\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49569b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(): #Otherwise the package might complain there is no \"boundary\" as we classify all as '1'\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plot_decision_regions(X, y, clf=clf, legend=2, colors = \"red,blue\", markers= \"o\");\n",
    "    ax=plt.gca();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b49e1c",
   "metadata": {},
   "source": [
    "## Answer: \n",
    "This data does not look like a good match for a sigmoid Kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91037780",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "**Assume that you will select one of the models you trained above. You compare the accuracy of each model and select the best-performing one. Are you over- or underestimating the error of the selected model? Why? If this is a problem, propose a way to fix it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6041e",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Parameter selection must be done carefully. In large projects, trying every possible setting and comparing them manually is not practical. Comparing results only on the training set favours models that overfit – for example, a high-degree polynomial may appear better than a lower-degree one, but this underestimates the true error. Using the test set for model choice also underestimates the error because it is no longer an independent evaluation. The proper approach is to evaluate models on a separate validation set or to use cross-validation, reserving the test set strictly for the final assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea3f62-d940-4fb3-afa4-60bbea8e7fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
