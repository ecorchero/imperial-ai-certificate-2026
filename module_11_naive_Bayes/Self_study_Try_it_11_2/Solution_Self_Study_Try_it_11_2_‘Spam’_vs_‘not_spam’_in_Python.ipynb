{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r_EEpmLUyZt"
   },
   "source": [
    "# Self-study try-it 11.2:  ‘Spam’ vs ‘not spam’ in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pRn7lklUyZ0"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment, you'll use the naïve Bayes technique to classify a set of text messages.\n",
    "\n",
    "Naive Bayes is a classification method based on Bayes’ theorem, which assumes that all predictors are independent of one another.\n",
    "\n",
    "Bayes’ theorem is written as:\n",
    "\n",
    "$$P(A | B) = \\frac{P(B|A)P(A)}{P(B)},$$\n",
    "\n",
    "where:\n",
    "\n",
    " - $P(A| B)$ is a conditional probability: the likelihood of event $A$ occurring given that $B$ is true\n",
    " - $P(B|A)$ is also a conditional probability: the likelihood of event $B$ occurring given that $A$ is true\n",
    " - $P(A)$ and $P(B)$ are the probabilities of observing $A$ and $B$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2Vivg6RUyZ3"
   },
   "source": [
    "## Outline\n",
    "\n",
    "- [Part 1: Importing the data set and exploratory data analysis](#part1)\n",
    "- [Part 2: Shuffling and splitting the text messages](#part2)\n",
    "- [Part 3: Building a naive Bayes classifier from scratch](#part3)\n",
    "- [Part 4: Explaining the code](#part4)\n",
    "- [Part 5: Training the classifier `train`](#part5)\n",
    "- [Part 6: Exploring the performance of the `train` classifier ](#part6)\n",
    "- [Part 7: Training the `train2` classifier ](#part7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmQvran_UyZ4"
   },
   "source": [
    "\n",
    "The pseudo-algorithm for naive Bayes can be summarised as follows:\n",
    "\n",
    "1. Load the training and test data.\n",
    "\n",
    "2. Shuffle and split the messages.\n",
    "\n",
    "3. Build a naive Bayes classifier from scratch.\n",
    "\n",
    "4. Train the classifier and explore the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmdHxDfIUyZ6"
   },
   "source": [
    "## Building a naive Bayes spam filter\n",
    "\n",
    "To build a naive Bayes spam filter for this assignment, you will use the `SMSSpamCollection` data set and complete the following steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdjOCwCNUyZ8"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1: Importing the data set and exploratory data analysis\n",
    "\n",
    "To begin, use the `pandas` library to import the data set. To do so, import `pandas` first. We read the file using the `.read_csv()` function by passing the name of the data set we want to read as a string.\n",
    "\n",
    "Notice that because the rows in the  data set are separated using a `\\t`, we specified the type of delimiter in the `.read_csv()` function (the default value is `,`). Additionally, we specified the list of column names to use (`\"label\"` and `\"sms\"`).\n",
    "\n",
    "- Begin by importing the `pandas` library.\n",
    "\n",
    "- Then, use the `.read_csv()` function to read the data set. Pass the name of the file as a string.\n",
    "\n",
    "- Because the rows in the file are separated by tabs `(\\t)`, specify the delimiter in the `.read_csv()` function. The default value is `,`.\n",
    "\n",
    "- Provide a list of column names as `\"label\"` and `\"sms\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teJk5MLKUyZ9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "messages = pd.read_csv('data/SMSSpamCollection.csv', sep = '\\t', names = [\"label\", \"sms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lieIzzqUyaA"
   },
   "source": [
    "Before applying any algorithm, it's good practice to perform some basic exploratory data analysis.\n",
    "\n",
    "- Start by viewing the first ten rows of the data frame `df` using the `.head()` function. By default, `.head()` shows the first five rows, but you can display more by passing an integer as the desired number of rows.\n",
    "\n",
    "- Complete the code cell below by passing 10 to `.head()` to view the first ten rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "DB2SD-SaUyaB",
    "outputId": "3a62960d-e777-462b-e0b5-7eaec6b1ecf6"
   },
   "outputs": [],
   "source": [
    "messages.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTQcNRnWUyaD"
   },
   "source": [
    "\n",
    "Next, use the properties `.shape` and `columns` and the function `.describe()` to retrieve more information about the data frame.\n",
    "\n",
    "Here's a brief description of what each of the above functions does:\n",
    "\n",
    "- `shape`: returns a tuple representing the dimensionality of the data frame\n",
    "\n",
    "- `columns`: returns the column labels of the data frame\n",
    "\n",
    "- `describe()`: returns summary statistics of the columns in the data frame provided, such as mean, count, standard deviation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QalUd6BmObF"
   },
   "source": [
    "### Question 1:\n",
    " Display the shape, columns and description of the data set, and assign them to `ans1a`, `ans1b` and `ans1c`, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CriQiBBeUyaE",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f29762f567d9ac18",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "9adb270c-c78b-4177-fe13-96fad1aadcc0"
   },
   "outputs": [],
   "source": [
    "\n",
    "ans1a = messages.shape\n",
    "ans1b = messages.columns\n",
    "ans1c = messages.describe()\n",
    "\n",
    "print(\"The shape of the dataset is \", ans1a)\n",
    "print(\"The columns of the dataset are \", ans1b)\n",
    "print(\"The description of the dataset is \", ans1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0SlO1yUUyaH"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2: Shuffling and splitting the text messages\n",
    "\n",
    "In this section, you will shuffle the messages and split them into a training set (2,500 messages), a validation set (1,000 messages) and a test set (all remaining messages).\n",
    "\n",
    "To begin, use the `pandas` function `sample` to shuffle the messages.\n",
    "\n",
    "### Question 2: Complete the code cell below\n",
    "\n",
    "- Complete the code cell below by applying the `.sample()` function to messages, with `frac = 1` and `random_state = 42`. The `frac` specifies the proportion of the data frame to return, while `random_state` sets a seed to ensure the results are reproducible.\n",
    "\n",
    "- Use the `reset_index()` function to reset the index of messages so that it aligns with the shuffled order. Be sure to include the appropriate argument.\n",
    "\n",
    "- Assign you answer to `ans2`.\n",
    "\n",
    "You can find the documentation about `.reset_index()` [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxY0CuPuUyaH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dde46a2995921e5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "f2a9cebb-ff30-434a-f5fe-33f557f6a3b0"
   },
   "outputs": [],
   "source": [
    "ans2 = messages.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print(ans2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWwDHP2NsbU_"
   },
   "outputs": [],
   "source": [
    "messages = ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTdbaCknUyaI"
   },
   "source": [
    "In the code cell below, the messages and their corresponding labels are defined.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UDarJyytwhB"
   },
   "outputs": [],
   "source": [
    "msgs = list(messages.sms)\n",
    "lbls =list(messages.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTgFYCVDtsAJ"
   },
   "source": [
    "### Question 3: Complete the code cell to split the labels into a training set, a validation set and a test set\n",
    "\n",
    "- Split the messages into three sets as instructed: a training set (2,500 messages), a validation set (1,000 messages) and a test set (the remaining messages).\n",
    "\n",
    "- Assign these to `trainingMsgs`, `valMsgs` and `testingMsgs`, respectively.\n",
    "\n",
    "- Split the corresponding labels in the same way and assign them to `trainingLbls`, `valLbls` and `testingLbls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBvF3mzzUyaI",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f48d001d2cb3002",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "ab2efd2f-9d4a-460c-8585-013f523b85e5"
   },
   "outputs": [],
   "source": [
    "trainingMsgs = msgs[:2500]\n",
    "valMsgs = msgs[2500:3500]\n",
    "testingMsgs = msgs[3500:]\n",
    "trainingLbls = lbls[:2500]\n",
    "valLbls = lbls[2500:3500]\n",
    "testingLbls = lbls[3500:]\n",
    "\n",
    "print(\"The number of training messages\", len(trainingMsgs))\n",
    "print(\"The number of validation messages\",len(valMsgs))\n",
    "print(\"The number of testing messages\", len(testingMsgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lzj0eieUyaJ"
   },
   "source": [
    "Following the above syntax, complete the code cell below to split the labels into a training set, a validation set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7-LbZSnUyaJ"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "### Part 3: Building a naive Bayes classifier from scratch\n",
    "\n",
    "While Python’s `scikit-learn` library has a naive Bayes classifier (see [here](https://scikit-learn.org/stable/modules/naive_bayes.html) for more information), it works with continuous probability distributions and assumes numerical features.\n",
    "\n",
    "Although it is possible to transform categorical variables into numerical features using a binary encoding, in this activity, you will build a naive Bayes classifier from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXu7IKuwUyaK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class NaiveBayesForSpam:\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:\n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]\n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C90ekJtWUyaL"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "### Part 4: Explaining the code\n",
    "\n",
    "Before exploring the code in Part 3 in further detail, it’s helpful to build some intuition about what a spam message might look like. Spam texts often include attention-grabbing words designed to tempt you to open them. You’ll also notice that they tend to use all capital letters and lots of exclamation marks.\n",
    "\n",
    "In the training phase, you use the `train` function to calculate and store the prior probabilities and likelihoods based on your training data. In naïve Bayes, that’s all the training involves.\n",
    "\n",
    "Next, you use the `predict` function that applies Bayes’ theorem to every word in the dictionary and uses the resulting posterior probabilities to classify each message as 'spam' or 'ham'.\n",
    "\n",
    "Finally, you call the `score` function to evaluate your classifier. It runs `predict` on multiple messages, compares the predictions to the `ground truth` labels and returns a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePNa5Lv8UyaL"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5: Training the `train` classifier\n",
    "\n",
    "Looking at the definition of the function `train`, you can see that the training functions require the `ham` and `spam` messages to be passed on separately.\n",
    "\n",
    "### Question 4: How do you construct the list `hammsgs`?\n",
    "\n",
    "How do you construct the list `hammsgs` so that it includes every message in `trainingMsgs` whose corresponding label in `trainingLbls` contains the substring 'ham'?\n",
    "\n",
    "You can do this by using `zip()` to pair each message with its label, then iterating through the pairs and selecting the messages where the label includes 'ham'.\n",
    "\n",
    "Hint: Use list comprehension to solve this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxYVs8bQUyaM",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23451e6f050957dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "56fd7783-a938-4afb-a6f7-5f8d12bd99ba"
   },
   "outputs": [],
   "source": [
    "hammsgs = [m for (m, l) in zip(trainingMsgs, trainingLbls) if 'ham' in l]\n",
    "\n",
    "print(hammsgs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyMA5vnPUyaM"
   },
   "source": [
    "### Question 5: How do you construct the list `spammsgs`?\n",
    "\n",
    "How do you construct the list `spammsgs` so that it includes every message in `trainingMsgs` whose corresponding label in `trainingLbls` contains the substring 'spam'?\n",
    "\n",
    "You can do this by using `zip()` to pair each message with its label, then iterating through the pairs and selecting the messages where the label includes 'spam'.\n",
    "\n",
    "Hint: Use list comprehension to solve this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5u1UcID4UyaM",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ecc635b184a152a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "6d890998-2308-4024-987f-2494d84386b9"
   },
   "outputs": [],
   "source": [
    "\n",
    "spammsgs = [m for (m, l) in zip(trainingMsgs, trainingLbls) if 'spam' in l]\n",
    "\n",
    "print(spammsgs[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZ4y8S5uUyaM"
   },
   "source": [
    "Run the cell below to see the number of `ham` and `spam` messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68Zl7e5vUyaN",
    "outputId": "8785a891-fa3e-493a-da53-c851fc031467"
   },
   "outputs": [],
   "source": [
    "print(len(hammsgs))\n",
    "print(len(spammsgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEXJzX5HUyaN"
   },
   "source": [
    "The sum should be 2,500 messages.\n",
    "\n",
    "### Question 6: Create the classifier for your analysis using the function `NaiveBayesForSpam`().\n",
    "\n",
    "- Complete the code cell below to create the classifier `clf`.\n",
    "\n",
    "- Train `hammsgs` and `spammsgs` using the function `train`.\n",
    "\n",
    "Hint: For this last part, look at the definition of the function `.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L534QNwJUyaN",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3566dfce691a9cf4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = NaiveBayesForSpam()\n",
    "clf.train(hammsgs, spammsgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJCHXKzgUyaN"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6: Exploring the performance of the `train` classifier\n",
    "\n",
    "You can explore the performance of the two classifiers on the *validation set* by using the function `.score()`.\n",
    "\n",
    "### Question 7: Complete the code cell below to compute the score and the confusion matrix.\n",
    "\n",
    "**Note: The results in the following sections may vary. This is expected and happens due to the random shuffling. Each shuffle produces slightly different outcomes. To ensure your results are reproducible, define `random_state` in the `sample` method when shuffling the data in [Part 2: Shuffling and splitting the text messages](#part2).**\n",
    "\n",
    "Note: This cell takes a couple of minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jhjs5rigUyaO",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-372182f98d166a80",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "7585a0fa-6e03-42d3-aede-e7e5a2f1d37c"
   },
   "outputs": [],
   "source": [
    "score, confusion = clf.score (valMsgs, valLbls)\n",
    "\n",
    "print(\"The overall performance is:\", score)\n",
    "print(\"The confusion matrix is:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8N-EseFUyaP"
   },
   "source": [
    "The data is not equally divided into the two classes. As a baseline, let’s check the success rate if you always predicted 'ham'.\n",
    "\n",
    "Run the code cell below to print the new score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ug4KeGzUyaP",
    "outputId": "5a0bbdd3-6b49-495d-ceec-dc4c91c500f5"
   },
   "outputs": [],
   "source": [
    "print('new_score', len([1 for l in valLbls if 'ham' in l]) / float (len ( valLbls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdDBftGnUyaP"
   },
   "source": [
    "\n",
    "You can also calculate the sample error by computing the score and the confusion matrix on the *training set*.\n",
    "\n",
    "### Question 8: Calculate the score and confusion matrix\n",
    "\n",
    "Calculate the score of the `trainingMsgs` and `trainingLbls` and assign it to `score_train` and `confusion_train`, respectively.\n",
    "\n",
    "Note: This cell may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dntfggtKUyaQ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-111537e323b5a8e9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "a8492919-907f-4dd6-d31e-d3f46a07a0c2"
   },
   "outputs": [],
   "source": [
    "score_train, confusion_train = clf.score (trainingMsgs, trainingLbls)\n",
    "\n",
    "\n",
    "print(\"The overall performance is:\", score_train)\n",
    "print(\"The confusion matrix is:\\n\", confusion_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y8nxaghUyaQ"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part7'></a>\n",
    "\n",
    "### Part 7: Training the `train2` classifier\n",
    "\n",
    "In this section, you will define a second classifier, `train2`, and compare its performances to the above classifier `train`.\n",
    "\n",
    "The `train2` method builds a vocabulary from all words, then filters it to keep only those whose likelihood of appearing in 'spam' is at least 20 times greater than in 'ham'. This creates a focused set of strong spam indicators for training and prediction.\n",
    "\n",
    "The `train2` classifier is defined in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXj-eDq1UyaQ"
   },
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam:\n",
    "    def train2 ( self , hamMessages , spamMessages) :\n",
    "            self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "            self.priors = np. zeros (2)\n",
    "            self.priors [0] = float (len (hamMessages)) / (len (hamMessages) +len( spamMessages ) )\n",
    "            self.priors [1] = 1.0 - self . priors [0]\n",
    "            self.likelihoods = []\n",
    "            spamkeywords = [ ]\n",
    "            for i, w in enumerate (self.words):\n",
    "                prob1 = (1.0 + len ([m for m in hamMessages if w in m])) /len ( hamMessages )\n",
    "                prob2 = (1.0 + len ([m for m in spamMessages if w in m])) /len ( spamMessages )\n",
    "                if prob1 * 20 < prob2:\n",
    "                    self.likelihoods.append([min (prob1 , 0.95) , min (prob2 , 0.95) ])\n",
    "                    spamkeywords . append (w)\n",
    "            self.words = spamkeywords\n",
    "            self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:\n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]\n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3T_9x6b8UyaR"
   },
   "source": [
    "### Question 9: Train the `train2` classifier\n",
    "\n",
    "- Train the `train2` classifier using the function `NaiveBayesForSpam()` and assign it to `clf2`.\n",
    "\n",
    "- Train `hammsgs` and `spammsgs` using the function `train2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEgW5xItUyaR",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d1c74966cb4d6ea",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "clf2 = NaiveBayesForSpam()\n",
    "clf2.train2(hammsgs, spammsgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FW_0JAxUyaR"
   },
   "source": [
    "### Question 10: Recompute the score and the confusion matrix on the *validation set* using the updated classifier.\n",
    "\n",
    "Note: This cell might a take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gx7oepdxUyaR",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a09f36f9472a01c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "0f2b1d30-fb5e-40a4-de90-7ee7959ed4a8"
   },
   "outputs": [],
   "source": [
    "\n",
    "score_2, confusion_2 = clf2.score(valMsgs, valLbls)\n",
    "\n",
    "print(\"The overall performance is:\", score_2)\n",
    "print(\"The confusion matrix is:\\n\", confusion_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q8vVd17zHb8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
