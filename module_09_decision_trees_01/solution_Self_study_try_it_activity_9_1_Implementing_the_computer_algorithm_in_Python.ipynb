{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRpjt6dZbzM-"
   },
   "source": [
    "# Self-study try-it activity 9.1: Implementing the computer algorithm in Python\n",
    "\n",
    "A decision tree is a hierarchical model that uses a sequence of decision rules, based on data features, to classify or predict outcomes. It is intuitive, easy to interpret and commonly used in machine learning for its ability to handle both categorical and numerical data effectively.\n",
    "\n",
    "\n",
    "#### Steps to implement decision trees:\n",
    "\n",
    "1. Calculate the Gini index.\n",
    "\n",
    "2. Split the data set.\n",
    "\n",
    "3. Compute the best split for the data set.\n",
    "\n",
    "4. Create a recursive function to build the tree.\n",
    "\n",
    "5. Use the tree to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qU17MvSykdQN"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsKqHh0qlQUk"
   },
   "outputs": [],
   "source": [
    "# 1. Calculate the Gini index for groups\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        labels = [row[-1] for row in group]\n",
    "        for class_val in classes:\n",
    "            p = labels.count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyUmRJ90lYRg"
   },
   "outputs": [],
   "source": [
    "# 2. Split the data set based on the feature index and split value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOIKi5GJlfwB"
   },
   "outputs": [],
   "source": [
    "# 3. Compute the best split for the data set\n",
    "def get_best_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    best_index, best_value, best_score, best_groups = None, None, float('inf'), None\n",
    "    for index in range(len(dataset[0]) - 1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eCZH-Q1mxdC"
   },
   "outputs": [],
   "source": [
    "# Create a terminal node value (most common class)\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return Counter(outcomes).most_common(1)[0][0]\n",
    "\n",
    "# 4. Create a recursive function to build the tree\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # Check for no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # Check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # Process the left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_best_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth + 1)\n",
    "    # Process the right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_best_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnFFlK7ynBCR"
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_best_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeE2g_NBvxJQ",
    "outputId": "30674eda-9286-4dbe-b1a2-4dc3815c3c2e"
   },
   "outputs": [],
   "source": [
    "# 5. Use tree to make a prediction \n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Example usage with a small data set\n",
    "dataset = [\n",
    "    [2.7, 2.5, 0],\n",
    "    [1.3, 1.8, 0],\n",
    "    [3.6, 2.9, 0],\n",
    "    [7.4, 3.1, 1],\n",
    "    [9.0, 3.3, 1],\n",
    "    [7.5, 0.5, 1],\n",
    "    [2.0, 2.2, 0],\n",
    "    [3.1, 3.0, 0],\n",
    "    [8.2, 3.5, 1],\n",
    "    [6.8, 2.8, 1]\n",
    "]\n",
    "\n",
    "tree = build_tree(dataset, max_depth=3, min_size=1)\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(tree, row)\n",
    "    print(f'Expected={row[-1]}, Predicted={prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ewO23gXnvxw"
   },
   "source": [
    "Extend these steps to the iris data set. Use the built-in functions created, and predict the first ten samples of the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuLqC_KJm-Rm"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujh1kEBboARS",
    "outputId": "3c11cb8e-d129-4fe8-fda8-c7b7716291b1"
   },
   "outputs": [],
   "source": [
    "# Load the iris data set and prepare the data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Combine X and y for processing\n",
    "dataset = [list(X[i]) + [y[i]] for i in range(len(y))]\n",
    "\n",
    "# Build the decision tree\n",
    "max_depth = 3\n",
    "min_size = 5\n",
    "tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "# Test the prediction on the first ten samples\n",
    "for i in range(10):\n",
    "    row = dataset[i]\n",
    "    prediction = predict(tree, row)\n",
    "    print(f\"Expected: {row[-1]}, Predicted: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DMYLcPHklk_"
   },
   "source": [
    "## To do:\n",
    "\n",
    "1. Experiment with different `max_depth` and `min_size` values to find the optimal parameters.\n",
    "\n",
    "2. Train a `scikit-learn` decision tree on the same data.\n",
    "\n",
    "3. Use entropy instead of the Gini index and write the code for entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUw1lRa5aJDV"
   },
   "source": [
    "1. Experiment with different `max_depth` and `min_size` values to find the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLPfIRyvaFy_",
    "outputId": "8ea35dc3-e2d5-4005-8067-d388eca6d9a2"
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    [2.7, 2.5, 0],\n",
    "    [1.3, 1.8, 0],\n",
    "    [3.6, 2.9, 0],\n",
    "    [7.4, 3.1, 1],\n",
    "    [9.0, 3.3, 1],\n",
    "    [7.5, 0.5, 1],\n",
    "    [2.0, 2.2, 0],\n",
    "    [3.1, 3.0, 0],\n",
    "    [8.2, 3.5, 1],\n",
    "    [6.8, 2.8, 1]\n",
    "]\n",
    "\n",
    "tree = build_tree(dataset, max_depth=15, min_size=2)\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(tree, row)\n",
    "    print(f'Expected={row[-1]}, Predicted={prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9owSAKZJcBCs"
   },
   "source": [
    "2: Train a scikit-learn decision tree on the iris data set with different `max_depth` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txKTwlxJb8Vl",
    "outputId": "42a2a4be-d6da-42f6-c02a-ad2a901c224f"
   },
   "outputs": [],
   "source": [
    "# Load the iris data set and prepare the data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Combine X and y for processing\n",
    "dataset = [list(X[i]) + [y[i]] for i in range(len(y))]\n",
    "\n",
    "# Build the decision tree\n",
    "max_depth = 15\n",
    "min_size = 1\n",
    "tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "# Test the prediction on the first ten samples\n",
    "for i in range(10):\n",
    "    row = dataset[i]\n",
    "    prediction = predict(tree, row)\n",
    "    print(f\"Expected: {row[-1]}, Predicted: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLW3uQh8cLK0"
   },
   "source": [
    "3. Use entropy instead of the Gini index and write the code for entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7BCz6nbcRtt"
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "def entropy(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    entropy = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        labels = [row[-1] for row in group]\n",
    "        for class_val in classes:\n",
    "            p = labels.count(class_val) / size\n",
    "            if p > 0:\n",
    "                score += p * log2(p)\n",
    "        entropy += -score * (size / n_instances)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DIdz1NgcY6b"
   },
   "outputs": [],
   "source": [
    "def get_best_split_entropy(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    best_index, best_value, best_score, best_groups = None, None, float('inf'), None\n",
    "    for index in range(len(dataset[0]) - 1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            entropy = entropy(groups, class_values)\n",
    "            if entropy < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], entropy, groups\n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZC9GIUXLcdP0",
    "outputId": "103cba50-4920-4143-a9ad-e96dae1005e7"
   },
   "outputs": [],
   "source": [
    "# Example usage with a small data set:\n",
    "dataset = [\n",
    "    [2.7, 2.5, 0],\n",
    "    [1.3, 1.8, 0],\n",
    "    [3.6, 2.9, 0],\n",
    "    [7.4, 3.1, 1],\n",
    "    [9.0, 3.3, 1],\n",
    "    [7.5, 0.5, 1],\n",
    "    [2.0, 2.2, 0],\n",
    "    [3.1, 3.0, 0],\n",
    "    [8.2, 3.5, 1],\n",
    "    [6.8, 2.8, 1]\n",
    "]\n",
    "\n",
    "tree = build_tree(dataset, max_depth=3, min_size=1)\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(tree, row)\n",
    "    print(f'Expected={row[-1]}, Predicted={prediction}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
