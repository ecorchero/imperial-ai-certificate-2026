{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z70pI11NAboS"
   },
   "source": [
    "# Self-study try-it activity 10.1: Selecting tree depth in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQSOK7b8AboX"
   },
   "source": [
    "    \n",
    "## Overview\n",
    "\n",
    "Decision trees are non-parametric supervised learning methods used for both classification and regression tasks. They structure decisions as a tree, comprising a root node, internal decision nodes, branches and leaf nodes, where each leaf represents a final prediction or classification. The tree recursively splits data into subsets based on feature values, forming simple if-then-else rules. \n",
    "\n",
    "While deeper trees can capture complex patterns, they also increase the risk of overfitting. Decision trees are intuitive and easy to visualise, require minimal data preparation and learn to approximate the target variable from data features.\n",
    "\n",
    "### About this assignment\n",
    "\n",
    "This assignment is designed to help you apply machine learning algorithms in Python. You’ll work within a Jupyter Notebook that includes embedded instructions, relevant Python concepts and starter code to guide your progress. Be sure to run all code cells before submitting your work. After completing the assignment, you are advised to compare your results with the provided solution file for self-assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAdRyXGhAboY"
   },
   "source": [
    "### About this notebook\n",
    "\n",
    "This notebook is structured into seven parts as follows:\n",
    "\n",
    "- [Part 1](#part1): Import the data set and exploratory data analysis \n",
    "\n",
    "- [Part 2](#part2): Translate the categorical predictors into numerical predictors\n",
    "\n",
    "- [Part 3](#part3): Shuffle the data set\n",
    "\n",
    "- [Part 4](#part4): Calculate the accuracy of the naive benchmark on the validation set.\n",
    "\n",
    "- [Part 5](#part5): Train a decision tree using the default settings\n",
    "\n",
    "- [Part 6](#part6): Train a decision tree using different maximum depths for the tree\n",
    "\n",
    "- [Part 7](#part7): Retrain the best classifier using all of the samples\n",
    "\n",
    "## Classification and regression trees\n",
    "\n",
    "The basic idea behind the algorithm for classification via regression trees can be summarised as follows:\n",
    "\n",
    "- Load the data set.\n",
    "\n",
    "- Select the best attribute using attribute selection measures to split the records.\n",
    "\n",
    "- Make that attribute a decision node, and break the data set into smaller subsets.\n",
    "\n",
    "- Start building the tree by repeating this process recursively for each child until one of the conditions will match:\n",
    "    - All the tuples belong to the same attribute value.\n",
    "    - There are no more remaining attributes.\n",
    "    - There are no more instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdpWayrpAboZ"
   },
   "source": [
    "### Predict defaults for student loans applications\n",
    "\n",
    "For this exercise, you will use the data set `loandata.csv` to predict defaults for student loans applications using regression trees. \n",
    "\n",
    "You will perform the following steps:\n",
    "\n",
    "1. Load the data set `loandata.csv` into Python.\n",
    "\n",
    "2. Translate the categorical predictors into numerical predictors.\n",
    "\n",
    "3. Split the data set into 50 per cent training data, 25 per cent validation data and 25 per cent test data.\n",
    "\n",
    "4. Calculate the accuracy of the naive benchmark on the validation set.\n",
    "\n",
    "5. Train a decision tree using the default settings.\n",
    "\n",
    "6. Retry the previous step using different maximum depths for the tree.\n",
    "\n",
    "7. Choose the most appropriate tree depth and justify your choice. Retrain the best classifier using all the samples from both the training and the validation set. Retrain the best classifier on all samples (including the test set), and describe the tree that you obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWjEWLOIAboa"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1: Import the data set and exploratory data analysis\n",
    "\n",
    "Begin by importing the necessary libraries. You will then use `pandas` to import the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6f8DUSuAbob"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree, ensemble\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSUtPaUmAboc"
   },
   "source": [
    "Assign the data frame to the variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izqtEmB2Abod"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/loandata.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TatVemQuAbod"
   },
   "source": [
    "\n",
    "Before building any machine learning algorithms, you need to explore the data.\n",
    "\n",
    "Begin by visualising the first ten rows of the data frame `df` using the function `.head()`. By default, `.head()` displays the first five rows of a data frame.\n",
    "\n",
    "Complete the code cell below by passing the desired number of rows as an `int` to the function `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "g7W_G1XtAboe",
    "outputId": "dfc2cfe2-4046-4874-d6cd-46aadd84b913"
   },
   "outputs": [],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MA2FgoQAbof"
   },
   "source": [
    "For your convenience, here is a brief description of what some of the columns represent:\n",
    "    \n",
    "- `field`: the field in which each student is taking their studies in\n",
    "\n",
    "- `graduationYear`: the year in which each student graduated\n",
    "\n",
    "- `loanAmount`: the amount each student owns\n",
    "\n",
    "- `selectiveCollege`: binary valued column: 1 for students who attend a selective college, 0 for students that do not\n",
    "\n",
    "- `sex`: sex of the student\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIJVmkIwAbof"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2: Translate the categorical predictors into numerical predictors\n",
    "\n",
    "\n",
    "In most of the well-established machine learning systems, categorical variables are handled naturally. However, when dealing with decision trees using `scikit-learn`, you need to encode (translate) categorical features into numerical features.\n",
    "\n",
    "Arguably, the easiest way to achieve this is by using the `pandas` function `get_dummies()`, which converts categorical variables into dummy/indicator variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrqpVr7VAbog"
   },
   "source": [
    "Complete the code cell below by using the data frame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYxXtfV4Abog"
   },
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncL7bL9JAbog"
   },
   "source": [
    "Because you are only interested in the students that will apply for a student loan, you will only need to keep the column `Default_Yes`.\n",
    "\n",
    "Complete the code cell below by using the function `.\n",
    "\n",
    "- Select the `bool` columns and convert them to `int` data type.\n",
    "\n",
    "- `drop()` on `df` to eliminate the *column* `Default_no`. The `axis` parameter in `.drop()` controls whether the function acts on rows or columns.\n",
    "\n",
    "- Convert the `Default_Yes` to `int` data type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXBcOBa8Aboh"
   },
   "source": [
    "Run the code cell below to visualise the new data frame with the encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhhH0E8QAboh"
   },
   "outputs": [],
   "source": [
    "bool_cols = df.select_dtypes('bool').columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuX3rWbeAboh"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['Default_No'], axis=1)\n",
    "y = df['Default_Yes'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKqn_DqTAboh"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "### Part 3: Prepare the target\n",
    "\n",
    " Convert the DataFrame to a `NumPy` array, and ensure that the last column contains integer values, which is often done to prepare target labels for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_tQUjtSAboh"
   },
   "outputs": [],
   "source": [
    "Xy=np.array(df)\n",
    "Xy[:,-1] = Xy[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdgkwsUSAboi"
   },
   "source": [
    "For reproducibility, set the random `seed = 2`. You can do this by using the `NumPy` function `random.seed()`. \n",
    "\n",
    "Assign your seed to the variable `seed`. \n",
    "\n",
    "Next, complete the code cell below by using the function `random.shuffle()` on $Xy$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eghkATQpAboi"
   },
   "outputs": [],
   "source": [
    "seed = np.random.seed(2)\n",
    "np.random.shuffle(Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNKo0ShMAboi"
   },
   "source": [
    "Before splitting the data into a training set, a test set and a validation set, you need to divide $Xy$ into two arrays: the first one, $X$, a 2D array containing all the predictors, and the second, $y$, is a 1D array with the response.\n",
    "\n",
    "Run the code cell below to generate $X$. Complete the remaining code to define $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGQ5qbqZAboi"
   },
   "outputs": [],
   "source": [
    "X=Xy[:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PM6zZ56uAboj"
   },
   "outputs": [],
   "source": [
    "y=Xy[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBmfJPqdAboj"
   },
   "source": [
    "Because you need to split the data into sets with certain dimensions according to the instructions given above, it would be useful to know how big the $X$ and $y$ are.\n",
    "\n",
    "Run the code cell below to retrieve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pleDOOG-Aboj",
    "outputId": "02b94ec6-7457-4a1f-d8b6-9af4f0a7c99e"
   },
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VacVHSsAboj"
   },
   "source": [
    "Next, you need to split the messages into 50 per cent training data, 25 per cent validation data and 25 per cent test data.\n",
    "\n",
    "Run the code below to split $X$ into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZzcsAGyAboj"
   },
   "outputs": [],
   "source": [
    "trainsize = 1000\n",
    "trainplusvalsize = 500\n",
    "X_train=X[:trainsize]\n",
    "X_val=X[trainsize:trainsize + trainplusvalsize]\n",
    "X_test=X[trainsize + trainplusvalsize:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bw1r665jAboj"
   },
   "source": [
    "Following the same syntax, complete the cell below to split `y` into training set, a validation set and a test set.\n",
    "\n",
    "**Hint:** Remember that `y` is a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WAkSNuHAboj"
   },
   "outputs": [],
   "source": [
    "y_train=y[:trainsize]\n",
    "y_val=y[trainsize:trainsize + trainplusvalsize]\n",
    "y_test=y[trainsize + trainplusvalsize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UzhkrFDAbok"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "### Part 4: Calculate the accuracy of the naive benchmark on the validation set\n",
    "\n",
    "In this part, you want to calculate the accuracy of the naive benchmark on both the $y$ training and validation sets. In other words, you want to understand how accurate your predictions would be, assuming that no one defaulted on their student loans.\n",
    "\n",
    "Accuracy can be computed by comparing actual test set values and predicted values. In this example, the formulae to compute accuracy are:\n",
    "\n",
    "$$\\text{acc_train} = 1 - \\frac{\\sum{\\text{y_train}}}{\\text{len(y_train)}},$$\n",
    "\n",
    "$$ \\text{acc_val} = 1 - \\frac{\\sum{\\text{y_val}}}{\\text{len(y_val)}}.$$\n",
    "\n",
    "Note that $\\frac{\\sum{\\text{y_train}}}{\\text{len(y_train)}}$ reflects the proportion of students who defaulted on their loan in the training set, and $\\frac{\\sum{\\text{y_val}}}{\\text{len(y_val)}}$ reflects the proportion of students who defaulted on their loan in the validation set.\n",
    "\n",
    "Compute the required accuracy in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nubaBMtpAbok"
   },
   "outputs": [],
   "source": [
    "acc_train = 1-sum(y_train)/len(y_train)\n",
    "acc_val = 1-sum(y_val)/len(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4InhueSWAbok"
   },
   "source": [
    "Run the code cell below to print the results to screen. What can you say about the baseline accuracy if you predict that no students defaulted (i.e. everyone belongs to the majority class)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dxNszcMAbok",
    "outputId": "e9a57d99-5f54-4c64-c8ab-67290d8da845",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ( 'Naïve guess train and validation', acc_train , acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gellnc1OAbok"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5: Train a decision tree using the default settings\n",
    "\n",
    "The easiest way to create a decision tree model is by using the function `DecisionTreeClassifier()`. This function is part of the `tree` module of `Scikit-learn` (`sklearn`).\n",
    "\n",
    "You will explore that there are ways to improve the accuracy of the tree. For now, let's build a classifier using the default settings.\n",
    "\n",
    "In the code cell below, use `DecisionTreeClassifier()` to define a classifier `clf` . \n",
    "\n",
    "Next, use the method `fit()` of your classifier to fit your training sets, `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "thXGEy884VO0",
    "outputId": "d1d1ae90-fffe-4461-8aea-368d7fe53d3d"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_train_categorical = lab.fit_transform(y_train)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa8TceT9Abol"
   },
   "source": [
    "Run the code cell below to visualise the new scores on the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kceHGPBdAbol",
    "outputId": "c76b18e5-0ff0-45d3-8417-e5b51fb5288d"
   },
   "outputs": [],
   "source": [
    "print ( 'Full tree guess train/validation ',clf.score(X_train, y_train),clf.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GBrGJ8EAbol"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6: Train a decision tree using  different maximum depths for the tree\n",
    "\n",
    "One way to optimise the decision tree algorithm is by adjusting the maximum depth of the tree. This process is an example of pre-pruning.\n",
    "\n",
    "In the following example, you will compute the score for a decision tree on the same data with `max_depth = 15`.\n",
    "\n",
    "You will begin by defining the variables `bestdepth` and `bestscore`, assuming the *worst case scenario*. Run the code cell below to initialise the variable as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bE1y7csxAbol"
   },
   "outputs": [],
   "source": [
    "bestdepth=-1\n",
    "bestscore=0\n",
    "max_depth = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlixZDIGAbol"
   },
   "source": [
    "Next, write a loop to progressively compute the new train/validation scores for different depths.\n",
    "\n",
    "Here is the pseudocode for the for loop you will need to implement:\n",
    "\n",
    "```python\n",
    "\n",
    "for i in range(max_depth):\n",
    "    # Compute a new classifier clf with depth = max_depth = i+1\n",
    "    # Fit the X and y training sets with the new classifier\n",
    "    # Compute the updated trainscore using .score() on the training set\n",
    "    # Compute the updated valscore using .score() on the validation set\n",
    "    # Print the scores\n",
    "    print ( 'Depth:', i+1, 'Training Score:', trainscore, 'Validation Score:', valscore)\n",
    "     \n",
    "    # If valscore is better than bestscore:\n",
    "        # Update the value of bestscore\n",
    "        # Increase bestdepth by one unit\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4gTgig9Abom",
    "outputId": "aba74192-b13a-4fc8-af40-6f9ab008e95d"
   },
   "outputs": [],
   "source": [
    "for i in range(max_depth):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=i+1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    trainscore=clf.score(X_train,y_train)\n",
    "    valscore=clf.score(X_val,y_val)\n",
    "    print( 'Depth:', i+1, 'Train Score:', trainscore, 'Validation Score:', valscore)\n",
    "\n",
    "    if valscore>bestscore:\n",
    "        bestscore=valscore\n",
    "        bestdepth=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tdULOXaAbon"
   },
   "source": [
    "Depths 2 to 4 yield identical high validation accuracy (0.872), with consistent training accuracy around 0.891. These depths represent the best balance of performance and generalizability.\n",
    "Starting from depth 5 onward, training accuracy continues to increase while validation accuracy declines, indicating the onset of overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4QG6BLkAbon"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part7'></a>\n",
    "\n",
    "### Part 7: Retrain the best classifier using all of the samples\n",
    "\n",
    "For the last part of this assignment, retrain the best classifier using all the samples from the training and the validation sets *together*.\n",
    "\n",
    "Begin by redefining your `X_trainval` and `y_trainval`. Below, the `X_trainval`function has been defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IA3095eAbon"
   },
   "outputs": [],
   "source": [
    "X_trainval=X[:trainsize + trainplusvalsize,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQenih4Abon"
   },
   "source": [
    "Following the syntax given above, define `y_trainval`.\n",
    "\n",
    "Again, remember that `y` is a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kcv3Xl5lAbon"
   },
   "outputs": [],
   "source": [
    "y_trainval=y[:trainsize + trainplusvalsize]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-A8VmvMAbon"
   },
   "source": [
    "To retrain the sets using the best classifier, redefine `clf`  using `DecisionTreeClassifier()` with `max_depth` equal to the `bestdepth` computed in Part 6. \n",
    "\n",
    "Next, fit the classifiers to the sets just defined above.\n",
    "\n",
    "Complete the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "RZEkT3G7Abon",
    "outputId": "6da821ea-bece-4820-f380-2d9e19437de8"
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=bestdepth)\n",
    "clf.fit(X_trainval,y_trainval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVanCeynAboo"
   },
   "source": [
    "Use the function `score()` to compute the score on both the test sets. Assign the result to `test_score`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NalKg-5rAboo"
   },
   "outputs": [],
   "source": [
    "test_score = clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THDARKTbAboo",
    "outputId": "cbc285f6-0a41-43e4-cb39-628528b7ed94"
   },
   "outputs": [],
   "source": [
    "print('testing set score', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ47GtlnAboo"
   },
   "source": [
    " This is the score of your best classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
