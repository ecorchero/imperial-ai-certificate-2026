{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required assignment 5.1-Applying the training set–validation set–test set approach\n",
    "\n",
    "In this notebook, you will use the training and validation sets to identify which model best fits the data. You will be working with the `train-test-split` approach from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps followed in the `train_test_validate` approach**\n",
    "\n",
    "1. Split the available data into a training set, a validation set and a test set.\n",
    "\n",
    "2. Fit each model separately on the training set.\n",
    "\n",
    "3. Evaluate each model separately on the validation set.\n",
    "\n",
    "4. Choose the model that performs best on the validation set.\n",
    "\n",
    "5. Estimate the performance of that model on the test set.\n",
    "\n",
    "6. Train the selected model again using all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e7a5bfcef1a037255ccdfd13f4917eb",
     "grade": false,
     "grade_id": "cell-c0f5f754de69ff54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the polynomial function to generate a data set. The function is defined as \n",
    "$$\n",
    "y = 3x^3 - 2x^2 + x + 5\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8429cc1faf1630d2bab224570db750ba",
     "grade": false,
     "grade_id": "cell-23cbabaa9167a7f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Example: generate synthetic data (replace with your own X, y)\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = 3 * X.squeeze()**3 - 2 * X.squeeze()**2 + X.squeeze() + 5 + np.random.randn(100) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split the data into training, testing and validation.\n",
    "\n",
    "#### **Question 1:** For the synthetic dataset, use the `train_test_split` function to split the data into 60% training , 20% validation and 20% test dataset.\n",
    "\n",
    "HINT: Since the `train_test_split()` function can only split the dataset into two parts, follow these steps:\n",
    "\n",
    "- The first split uses 20% of the data for the test dataset.\n",
    "\n",
    "- The second split uses 25% of the previous training set as the test dataset.\n",
    "\n",
    "- The final proportions of the train:validate:test is 60:20:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8294fff5c35dc168a3c47311a1b4b9be",
     "grade": false,
     "grade_id": "cell-ac3bc07c2bb664da",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Split Shapes ---\n",
      "X_train shape\n",
      " (60, 1)\n",
      "X_val shape\n",
      " (20, 1)\n",
      "X_test shape\n",
      " (20, 1)\n",
      "y_train shape\n",
      " (60,)\n",
      "y_val shape\n",
      " (20,)\n",
      "y_test shape\n",
      " (20,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, testing and validation.\n",
    "\n",
    "###GRADED\n",
    "\n",
    "# First split: Separate out the 20% test set (remaining 80% for training and validation)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Second split: 25% of 80% = 60-20 split (20% of original dataset for validation, 80% training)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shapes to verify the split\n",
    "print(\"--- Data Split Shapes ---\")\n",
    "print(\"X_train shape\\n\", X_train.shape)   # Should be 60\n",
    "print(\"X_val shape\\n\", X_val.shape)       # Should be 20\n",
    "print(\"X_test shape\\n\", X_test.shape)     # Should be 20\n",
    "print(\"y_train shape\\n\", y_train.shape)\n",
    "print(\"y_val shape\\n\", y_val.shape)\n",
    "print(\"y_test shape\\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c01848bfdbfbf9aefbe410c31455a5cc",
     "grade": true,
     "grade_id": "cell-42fafea4440ebd99",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit each model separately on the training dataset.\n",
    "\n",
    "#### **Question 2:** For the synthetic dataset, use the `LinearRegression()` model.\n",
    "\n",
    "HINT: Use the `model.fit()` function to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbe11b163995401688df4dda04d77139",
     "grade": false,
     "grade_id": "cell-79a1a81378634f2b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Model for degree 1 fitted and polynomial features transformed.\n",
      "  - Model for degree 2 fitted and polynomial features transformed.\n",
      "  - Model for degree 3 fitted and polynomial features transformed.\n",
      "  - Model for degree 4 fitted and polynomial features transformed.\n",
      "  - Model for degree 5 fitted and polynomial features transformed.\n",
      "  - Model for degree 6 fitted and polynomial features transformed.\n"
     ]
    }
   ],
   "source": [
    "###GRADED CELL\n",
    "val_errors = {}\n",
    "models = {}\n",
    "\n",
    "for degree in range(1, 7): #loop for degrees 1, 2, 3, 4, 5, 6 (7 not included)\n",
    "    # Create polynomial features for the current degree\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "\n",
    "    # Transform the training data to include polynomial features\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    # .fit_transform() learns the polynomial features from X_train and then applies the transformation\n",
    "\n",
    "    # Transform the validation data using the *same* polynomial features learned from training data\n",
    "    X_val_poly = poly.transform(X_val)\n",
    "    # .transform() NOT .fit_transform(), to avoid data leakage from the validation set\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "    # Initialize a Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the Linear Regression model on the transformed training data\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Store the fitted model and its corresponding polynomial transformer\n",
    "    # We store both because we'll need the 'poly' object to transform new data (validation/test) later\n",
    "    models[degree] = (model, poly)\n",
    "\n",
    "    print(f\"  - Model for degree {degree} fitted and polynomial features transformed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72bd23b0ffe1195bfba27c2b89b35562",
     "grade": true,
     "grade_id": "cell-04ea5186dc485cd6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Evaluate each model separately on the validation dataset.\n",
    "\n",
    "#### **Question 3:** Evaluate on the validation set and use the `mean_squared_error()` to compute the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e03b1f8972933fb19ec0216453e3645",
     "grade": false,
     "grade_id": "cell-624975e0ac102262",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Degree 6: Validation MSE = 8060.76\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "# Use the fitted model to make predictions on the transformed validation data\n",
    "y_val_pred = model.predict(X_val_poly)\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) between predictions and actual validation labels\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Store the MSE for the current degree in the val_errors dictionary\n",
    "val_errors[degree] = mse\n",
    "\n",
    "# Print the validation MSE for the current degree\n",
    "print(f\"  - Degree {degree}: Validation MSE = {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ee5f399625a8e3c16d5042690415f60",
     "grade": true,
     "grade_id": "cell-9c9a9de9e736ad76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Choose the model that performs best on the validation set.\n",
    "\n",
    "#### **Question 4**: Choose the best model which has the min error and print the degree of that model.\n",
    "\n",
    "HINT: Use `key=val_errors.get` to use the dictionary values (the validation errors) for comparison, and not the keys themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6119abbbe098a0ddfbc12f89104639",
     "grade": false,
     "grade_id": "cell-c8c9272fd9e0d688",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best polynomial degree: 6\n"
     ]
    }
   ],
   "source": [
    "# Choose the best model which has the min error\n",
    "\n",
    "###GRADED\n",
    "best_degree = min(val_errors, key=val_errors.get) # Use key=val_errors.get to use the dictionary values\n",
    "#(the validation errors) for comparison, and not the keys themselves.\n",
    "\n",
    "print(f\"Best polynomial degree: {best_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32fe1921dd460fa137d3052910316c5d",
     "grade": true,
     "grade_id": "cell-b66f63846acbe2f8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Estimate the performance of that model on the test set.\n",
    "\n",
    "#### **Question 5**: Estimate the performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "735da9eead84c2a54a8a5c06506657c5",
     "grade": false,
     "grade_id": "cell-a245ff314c0c0b24",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for best model (degree 6): 6063.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "###GRADED\n",
    "\n",
    "# Retrieve the best model and its corresponding polynomial transformer\n",
    "best_model, best_poly = models[best_degree]\n",
    "\n",
    "# Transform the test data using the polynomial features learned by the best model's transformer\n",
    "X_test_poly = best_poly.transform(X_test)\n",
    "# It's crucial to use .transform() here, not .fit_transform(), to avoid data leakage\n",
    "\n",
    "# Use the best fitted model to make predictions on the transformed test data\n",
    "y_test_pred = best_model.predict(X_test_poly)\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) between predictions and actual test labels\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test MSE for best model (degree {best_degree}): {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02f5e88ddfe96a777ce2afad26cdb3a5",
     "grade": true,
     "grade_id": "cell-61c489b38b5ffd95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Retrain the best model on all available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d3b071fdee8ba3c48a35f8d7da360cd",
     "grade": false,
     "grade_id": "cell-1790ed46615feb52",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrained best polynomial model (degree 6) on all data.\n"
     ]
    }
   ],
   "source": [
    "best_poly_full = PolynomialFeatures(degree=best_degree)\n",
    "X_full_poly = best_poly_full.fit_transform(X)\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_full_poly, y)\n",
    "print(f\"Retrained best polynomial model (degree {best_degree}) on all data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
