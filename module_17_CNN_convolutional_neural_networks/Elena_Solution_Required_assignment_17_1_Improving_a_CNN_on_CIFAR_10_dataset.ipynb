{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2F6uMwSLIjM"
   },
   "source": [
    "# Required assignment 17.1 Improving a CNN on CIFAR-10 dataset\n",
    "\n",
    "In this assignment, you will implement and train a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset—a collection of 60,000 32×32 color images across 10 categories such as airplanes, cats, and trucks.\n",
    "\n",
    "By performing this assignment, you will gain an understanding of how to:\n",
    "- Adapt a classic CNN architecture (LeNet) for RGB image classification.\n",
    "\n",
    "- Prepare and augment image datasets for model training.\n",
    "\n",
    "- Train a CNN model using stochastic gradient descent.\n",
    "\n",
    "- Evaluate model performance on unseen test data.\n",
    "\n",
    "- Explore how different activation functions affect network performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_i_-GIP3RpSG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import the necessary PyTorch and torchvision modules.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUe-pVrTR3jp"
   },
   "source": [
    "## 1. Data Preprocessing and Loading\n",
    "- Augment training data with random horizontal flips\n",
    "- Normalize both training and test data using CIFAR-10 mean and std\n",
    "- Load CIFAR-10 using torchvision datasets\n",
    "- Use DataLoader for batching (128 for train, 100 for test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MtFsAnwSdg4",
    "outputId": "3dd76f2d-a698-4b6b-c708-d428379b0271"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkiPAcU9AXZE"
   },
   "source": [
    "## 2. Define LeNet Model\n",
    " - First, define the baseline LeNet model\n",
    " - In question 1, you will be asked to make some modifications to the model defined below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiXVu3y0ILTq"
   },
   "source": [
    "```\n",
    "class LeNetBaseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetBaseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yepYRegdHmlr"
   },
   "source": [
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.sigmoid(self.conv1(x)))\n",
    "        x = self.pool(self.sigmoid(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3reQ3O0IYQM"
   },
   "source": [
    "### Question 1: Modify the `LeNetBaseline(nn.Module)` with the following variations.\n",
    "\n",
    "You are required to implement a modified Convolutional Neural Network (CNN) architecture for CIFAR-10 image classification, based on the classic LeNet design with the following specifications:\n",
    "\n",
    "1. Model Architecture Setup:\n",
    "\n",
    "- The network should consist of three convolutional layers:\n",
    "\n",
    "  -   conv1: 3 input channels, 16 output channels, kernel size 5×5, padding 2.\n",
    "\n",
    "  - conv2: 16 input channels, 32 output channels, kernel size 5×5, padding 2.\n",
    "\n",
    "  - conv3: 32 input channels, 64 output channels, kernel size 3×3, padding 1.\n",
    "- Use Max Pooling (`MaxPool2d`) with kernel size 2×2 and stride 2 after each convolution.\n",
    "\n",
    "2. Fully Connected Layers:\n",
    "\n",
    "- Flatten the feature maps after the last pooling layer. Account for the size reduction caused by pooling and convolutions.\n",
    "\n",
    "- Add three fully connected (Linear) layers as follows:\n",
    "\n",
    "  - fc1: input features matching flattened size, output 120 units.\n",
    "\n",
    "  - fc2: input 120 units, output 84 units.\n",
    "\n",
    "  - fc3: input 84 units, output 10 units (number of CIFAR-10 classes).\n",
    "\n",
    "3. Activation Functions and Regularization:\n",
    "\n",
    "- Instead of using the sigmoid activation function, this model will use ReLU (nn.ReLU()). Define this in the __init__ constructor.\n",
    "\n",
    "- This model will apply a dropout layer with a probability of 0.5 after the fc1 and fc2 layers to reduce overfitting. In the __init__ constructor, give the model a \"dropout\" attribute with an appropriate nn.Dropout().\n",
    "\n",
    "4. Forward Pass Logic:\n",
    "\n",
    "- Forward propagate input x by successively applying convolution → ReLU → max pooling for each of the three convolutional layers.\n",
    "\n",
    "- Flatten the output tensor appropriately.\n",
    "\n",
    "- Pass the flattened vector through the fully connected layers while applying ReLU activation and dropout after the first two fully connected layers.\n",
    "\n",
    "- Output class scores from the final layer without activation (as this will be combined with a loss function like CrossEntropyLoss).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "id": "fAYyrUxnJNMU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baa8a36fe1312b895fab657657986e7b",
     "grade": false,
     "grade_id": "cell-acf7f68cbf8747b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "###GRADED CELL\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "class LeNetModified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetModified, self).__init__()\n",
    "        \n",
    "        # ----- Convolutional part -----\n",
    "        # conv1: 3 -> 16, kernel 5x5, padding 2\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        # conv2: 16 -> 32, kernel 5x5, padding 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        # conv3: 32 -> 64, kernel 3x3, padding 1\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # After 3×(conv + 2×2 pool), 32x32 → 16x16 → 8x8 → 4x4\n",
    "        # channels = 64, so flattened size = 64 * 4 * 4 = 1024\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)   # 10 CIFAR-10 classes\n",
    "\n",
    "        # shared layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dropout with p = 0.5 after fc1 and fc2\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution + ReLU + MaxPool (three times)\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(-1, 64 * 4 *4)\n",
    "\n",
    "        # Fully connected layers with ReLU + Dropout on first two\n",
    "        # x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "\n",
    "        # Final classification layer: raw scores (logits)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UKvTFn75MdCu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "371aad7f3c03d12675e7ffc03ab256c2",
     "grade": true,
     "grade_id": "cell-91a9cd66217937b8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez2Y75AENa1t"
   },
   "source": [
    "\n",
    "## 4. Setup Training Components\n",
    " - Choose GPU if available\n",
    " - Use CrossEntropyLoss\n",
    "\n",
    "### Question 2: In the place of Stochastic Gradient Descent (SGD)optimizer\n",
    "- Define an `Adam` optimizer with a lower `lr` of 0.001 and no momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "X1ih4j9cNmzh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63b74da3034f86733e055ca93cf2fea7",
     "grade": false,
     "grade_id": "cell-337adc413d44d7b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED CELL\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LeNetModified().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# Adam optimizer with lr = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nKRKB2T_P_qE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b497bad016082ad4e45253961ec968d2",
     "grade": true,
     "grade_id": "cell-1eae9da3dbc881c3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0Zy1tNgRFeB"
   },
   "source": [
    "## 5. Train the Baseline Model\n",
    " - Train for 5 epochs\n",
    " - Print average loss per epoch\n",
    " - NOTE: This cell might take a longer time to execute. If you see message \"File save error with Invalid response:429\" ignore this message by pressing the close button. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "YgLxhELoRQqO",
    "outputId": "04b70365-0676-40ea-812e-a38b81076f27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEFMY6uHRXky"
   },
   "source": [
    "## 6. Evaluate Baseline Model\n",
    "- Calculate accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_L1GmZMRieu",
    "outputId": "9415a562-0290-4565-e329-66cc0a4e966c"
   },
   "outputs": [],
   "source": [
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Baseline LeNet Accuracy on CIFAR-10 test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdioIuYgRvUf"
   },
   "source": [
    "### Question 3:\n",
    "Why is it important to normalize CIFAR-10 images during preprocessing in this network?\n",
    "\n",
    "A) To convert the images from RGB to grayscale.\n",
    "\n",
    "B) To scale pixel values to a range that improves model training convergence.\n",
    "\n",
    "C) To increase the dataset size by adding augmented images.\n",
    "\n",
    "D) To reduce the spatial resolution of the images.\n",
    "\n",
    "Set the value of `ans3` to \"A\", \"B\", \"C\" or \"D\" depending on your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "2VxMRxUHSItj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3911f2833a998e753895f030d28ffbf9",
     "grade": false,
     "grade_id": "cell-67b7e50b734ff7d4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "###GRADED CELL\n",
    "ans3 = ...\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "ans3 = \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a0Jgq_1aSZce",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1cc4a81e3ccedf254be891918bb8aca",
     "grade": true,
     "grade_id": "cell-ba89db7243f426f1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7XldttiSpaB"
   },
   "source": [
    "### Question 4:\n",
    "In the LeNet architecture for CIFAR-10, what is the purpose of the final fully connected layer (fc3)?\n",
    "\n",
    "A) To reduce the number of input channels for the next layer.\n",
    "\n",
    "B) To apply an activation function (sigmoid or ReLU).\n",
    "\n",
    "C) To map the learned features to the class scores for the 10 CIFAR-10 categories.\n",
    "\n",
    "D) To perform the convolution operation on feature maps.\n",
    "\n",
    "Set the value of `ans4` to \"A\", \"B\", \"C\" or \"D\" depending on your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "tmeKQJalUn-C",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68f9fcd2bba475cc221031ddd33a3aca",
     "grade": false,
     "grade_id": "cell-e6838f241e23aa4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "###GRADED CELL\n",
    "ans4 = None\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "ans4 = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kXDe6jlmU01C",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1e43fc1ddbed6210d7957a7660c23f7",
     "grade": true,
     "grade_id": "cell-c3ab2224f2222ff7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
