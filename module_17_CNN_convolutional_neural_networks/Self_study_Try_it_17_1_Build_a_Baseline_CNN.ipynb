{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RofCjfbYrvue"
   },
   "source": [
    "# Self-study Try_it 17.1: Build a baseline CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOpVdFrnsHjY"
   },
   "source": [
    "## Introduction: Training a CNN on CIFAR-10 with LeNet\n",
    "\n",
    "In this lesson, you'll implement and train a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset—a collection of 60,000 32×32 color images across 10 categories such as airplanes, cats, and trucks.\n",
    "\n",
    "We'll use a modified version of the classic **LeNet architecture**, originally designed for digit recognition, and adapt it for CIFAR-10's RGB images and diverse classes. This model includes convolutional layers for feature extraction, pooling layers for spatial reduction, and fully connected layers for classification.\n",
    "\n",
    "### What You'll Do:\n",
    "- Load and normalize CIFAR-10 data using `torchvision`\n",
    "- Define the LeNet architecture using `torch.nn`\n",
    "- Train the model using stochastic gradient descent (SGD)\n",
    "- Evaluate its performance on unseen test data\n",
    "\n",
    "This hands-on implementation will help you understand how CNNs learn visual patterns, how training progresses over epochs, and how to measure model accuracy. By the end, you'll have a working image classifier and a solid foundation for deeper model diagnostics and improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtztKnsUsNoy"
   },
   "source": [
    "Before building and training our CNN, we import essential PyTorch and torchvision libraries:\n",
    "\n",
    "- `torch`: Core PyTorch library for tensor operations and GPU acceleration.\n",
    "- `torch.nn`: Provides modules and classes for building neural networks (e.g., layers, activations).\n",
    "- `torch.optim`: Contains optimization algorithms like SGD and Adam for training models.\n",
    "- `torchvision`: Offers datasets (like CIFAR-10), pretrained models, and image utilities.\n",
    "- `torchvision.transforms`: Enables preprocessing and augmentation of image data (e.g., normalization, flipping).\n",
    "\n",
    "These libraries form the backbone of our deep learning workflow—handling everything from data loading to model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4hAeAs1psYJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT2eEZ-Is7gc"
   },
   "source": [
    "## Defining the LeNet Architecture for CIFAR-10\n",
    "\n",
    "In this section, we define a modified version of the classic **LeNet** architecture, adapted for the CIFAR-10 dataset. CIFAR-10 images are RGB (3 channels) and sized 32×32 pixels, so the original LeNet (designed for grayscale digits) requires adjustments.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- `conv1`: First convolutional layer with 6 filters and 5×5 kernels. Padding is added to preserve spatial dimensions.\n",
    "- `pool`: Average pooling layer with 2×2 kernel and stride 2, used to reduce spatial resolution.\n",
    "- `conv2`: Second convolutional layer with 16 filters.\n",
    "- `fc1`, `fc2`, `fc3`: Fully connected layers that map the extracted features to class scores.\n",
    "- `sigmoid`: Activation function used throughout, consistent with the original LeNet design.\n",
    "\n",
    "### Forward Pass Logic:\n",
    "\n",
    "1. Apply `conv1` → `sigmoid` → `pool`\n",
    "2. Apply `conv2` → `sigmoid` → `pool`\n",
    "3. Flatten the feature map to a vector\n",
    "4. Pass through `fc1` → `sigmoid`\n",
    "5. Pass through `fc2` → `sigmoid`\n",
    "6. Output class scores via `fc3`\n",
    "\n",
    "This architecture is simple yet effective for small-scale image classification tasks. While modern CNNs often use ReLU and max pooling, this version preserves the historical structure of LeNet for educational purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UW9wiQWUsr03"
   },
   "outputs": [],
   "source": [
    "# Define LeNet architecture for CIFAR-10\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)  # 3 input channels for CIFAR-10, added padding\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # Adjusted for CIFAR-10 image size after conv/pool (16*6*6)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # CIFAR-10 has 10 classes\n",
    "        self.sigmoid = nn.Sigmoid()  # Using sigmoid as in original LeNet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.sigmoid(self.conv1(x)))\n",
    "        x = self.pool(self.sigmoid(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6) # Adjusted for CIFAR-10 image size after conv/pool (16*6*6)\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEgshIbUuDYA"
   },
   "source": [
    "## Data Preprocessing and Augmentation\n",
    "\n",
    "To prepare CIFAR-10 images for training:\n",
    "\n",
    "- **Training data** is augmented with random horizontal flips to improve generalization.\n",
    "- Both **training and test data** are converted to tensors and normalized using dataset-specific mean and standard deviation values.\n",
    "\n",
    "This ensures consistent input scaling and helps the model learn more robust features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViGHNk22tQRe"
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNlc855SuWBe"
   },
   "source": [
    "## Loading the CIFAR-10 Dataset\n",
    "\n",
    "We use `torchvision.datasets.CIFAR10` to load the CIFAR-10 image dataset, which contains 60,000 32×32 color images across 10 classes.\n",
    "\n",
    "- **Training set**: Loaded with data augmentation and shuffled for better generalization.\n",
    "- **Test set**: Loaded without augmentation and kept in order for evaluation.\n",
    "- `DataLoader` wraps the datasets to enable efficient batching and parallel loading.\n",
    "\n",
    "This setup ensures smooth training and evaluation using mini-batches and GPU acceleration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYXv3lYJuKKb"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xzvjn8lungK"
   },
   "source": [
    "## Model Initialization and Training Setup\n",
    "\n",
    "Before training, we set up the key components:\n",
    "\n",
    "- **Device selection**: Automatically uses GPU (`cuda`) if available, otherwise defaults to CPU.\n",
    "- **Model instantiation**: The LeNet architecture is created and moved to the selected device.\n",
    "- **Loss function**: `CrossEntropyLoss` is used for multi-class classification.\n",
    "- **Optimizer**: Stochastic Gradient Descent (SGD) with a learning rate of 0.1 and momentum of 0.9 helps the model converge efficiently.\n",
    "\n",
    "This setup ensures the model is ready for training with appropriate computational resources and learning configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJmNrAyfucHa"
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYgQp51Zu3WW"
   },
   "source": [
    "## Training the CNN Model\n",
    "\n",
    "This loop trains the LeNet model over 10 epochs using the CIFAR-10 training data.\n",
    "\n",
    "### What Happens Each Epoch:\n",
    "- `net.train()`: Sets the model to training mode.\n",
    "- Data is loaded in batches and moved to the selected device (CPU/GPU).\n",
    "- Gradients are reset using `optimizer.zero_grad()`.\n",
    "- The model makes predictions (`outputs = net(inputs)`).\n",
    "- Loss is computed using `CrossEntropyLoss`.\n",
    "- Backpropagation updates the model weights via `loss.backward()` and `optimizer.step()`.\n",
    "\n",
    "The average loss per epoch is printed to monitor training progress and convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsMxLVlVus9d",
    "outputId": "71cceccd-b949-419d-ae56-d8f8b0234d5b"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):  # 10 epochs\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3SbxwgFvI3R"
   },
   "source": [
    "##  Evaluating Model Performance on the Test Set\n",
    "\n",
    "After training, we switch the model to evaluation mode using `net.eval()` to disable dropout and batch normalization (if present).\n",
    "\n",
    "###  Evaluation Steps:\n",
    "- Disable gradient computation with `torch.no_grad()` for efficiency.\n",
    "- Loop through the test data and make predictions.\n",
    "- Use `torch.max(outputs, 1)` to get the predicted class for each image.\n",
    "- Compare predictions with true labels to count correct classifications.\n",
    "\n",
    "Finally, we compute and print the overall test accuracy as a percentage—this gives a quick snapshot of how well the model generalizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIQsckOIvAJe",
    "outputId": "b584274a-854a-4bc2-e023-ccae639e8d4f"
   },
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on CIFAR-10 test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfZhZLo5eucv"
   },
   "source": [
    "## Revising the Model\n",
    "\n",
    "In this section, we'll explore how implementing different activation functions in our LeNet model affects the CNN's performance.\n",
    "\n",
    "Separately, we will:\n",
    "\n",
    "- Update the model to use the `ReLU` activation function. Train the model and compare the final accuracy.\n",
    "- Update the model to use the `tanh` activation function. Train the model and compare the final accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisit the LeNet class we defined earlier and update the activation function.\n",
    "# In the __init__ method, replace self.sigmoid = nn.Sigmoid() with the below activation function\n",
    "self.relu = nn.ReLU()\n",
    "\n",
    "# Update the model's forward method so that it calls the new activation function.\n",
    "\n",
    "# Then follow the steps to train the model again and note down its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = self.pool(self.relu(self.conv1(x)))\n",
    "x = self.pool(self.relu(self.conv2(x)))\n",
    "x = self.relu(self.fc1(x))\n",
    "x = self.relu(self.fc2(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try revising and training the model with the `tanh` activation function.\n",
    "self.tanh = nn.Tanh()\n",
    "\n",
    "# Again, update the LeNet model class by adding the new activation function to the init block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = self.pool(self.tanh(self.conv1(x)))\n",
    "x = self.pool(self.tanh(self.conv2(x)))\n",
    "x = self.tanh(self.fc1(x))\n",
    "x = self.tanh(self.fc2(x))\n",
    "# Update the model's forward method again so that it calls the new activation function.\n",
    "\n",
    "# Then train the model again and note down its accuracy with the tahn activation function."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
