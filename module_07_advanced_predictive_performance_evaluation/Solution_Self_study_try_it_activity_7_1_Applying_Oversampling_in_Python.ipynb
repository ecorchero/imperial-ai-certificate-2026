{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed39c2de",
   "metadata": {
    "id": "_ikgGD7piSaB"
   },
   "source": [
    "# Self-study try-it activity 7.1: Applying oversampling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77d7c3",
   "metadata": {
    "id": "d74e314d"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecd515",
   "metadata": {
    "id": "37205538"
   },
   "source": [
    "# Oversampling\n",
    "\n",
    "In this notebook, you’ll explore how oversampling can improve predictions when the class of interest has significantly fewer examples than other classes. This is a common issue that is known as class imbalance. This situation often arises in real-world contexts such as fraud detection or diagnosing rare diseases.\n",
    "\n",
    "The notebook is organised into three parts:\n",
    "\n",
    "- Part one: create training and validation sets using random sampling (no oversampling).\n",
    "\n",
    "- Part two: create training and validation sets using stratified sampling (with oversampling).\n",
    "\n",
    "- Part three: compare the results from parts one and two by answering a few questions in the markdown cell below.\n",
    "\n",
    "**Note: All required packages have already been imported into the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be67fc95",
   "metadata": {
    "id": "836f9172"
   },
   "source": [
    "## Data creation\n",
    "\n",
    "You’ll use a handy function from scikit-learn called `make_classification` to create a synthetic data set for testing classification models. This is especially useful when you need a quick data set to experiment with or want to compare different approaches.\n",
    "\n",
    "**The class of interest in this exercise is class 0, which includes all points for which y = 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c4243",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "c80fa273",
    "outputId": "09dfa787-33a0-4ddc-f8b7-418d34d74154",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.05, 0.95],\n",
    "                           class_sep=0.8, random_state=0)\n",
    "\n",
    "\n",
    "colors = ['#ef8a62' if v == 0 else '#f7f7f7'  for v in y]\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#ef8a62', edgecolor='black', label='Class 0'),\n",
    "    Patch(facecolor='#f7f7f7', edgecolor='black', label='Class 1'),\n",
    "    ]\n",
    "plt.legend(handles=legend_elements, title='Classes')\n",
    "kwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\n",
    "fig = plt.Figure(figsize=(12,6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colors, **kwarg_params)\n",
    "sns.despine()\n",
    "\n",
    "print(f'Number of data points in first class {len(X[np.where(y==0)])}')\n",
    "print(f'Number of data points in second class {len(X[np.where(y==1)])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f9551",
   "metadata": {
    "id": "4a41e22d"
   },
   "source": [
    "## Machine learning model\n",
    "\n",
    "You’ll use a support vector machine (SVM) classifier as the model for this exercise. You'll explore how SVMs work later in the programme, but for now, you'll work with the built-in implementation from scikit-learn. Use the provided `train_and_predict` function to train the model and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57394bcb",
   "metadata": {
    "id": "af72ac02"
   },
   "outputs": [],
   "source": [
    "# Do not edit this cell\n",
    "\n",
    "def train_and_predict(train, validation):\n",
    "    \"\"\"Function to fit sklearn support vector classification model and make predictions on the validation set\n",
    "    :param train: the training set as a numpy array of length N_trainx(D+1) where N_train is the number of\n",
    "    training points and D is the dimensions of X (in this case 2). The extra column is the y values.\n",
    "    param validation: the validation set as a numpy array similar to train but for the validation set\"\"\"\n",
    "\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train[:, :2], train[:, 2])\n",
    "    predictions = clf.predict(validation[:, :2])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970b180",
   "metadata": {
    "id": "438466d6"
   },
   "source": [
    "## Part one\n",
    "\n",
    "First, you’ll test how the model performs without applying any oversampling.\n",
    "\n",
    "### To do: ###\n",
    "\n",
    "1. Split the data set into 50 per cent training and 50 per cent validation sets, ignoring the class labels (i.e. no oversampling). For both sets, ensure that the first column contains the input X and the second column contains the target y, formatted as a NumPy array [X1, y].\n",
    "\n",
    "2. Use the `train_and_predict` function to train the model on the training set and make predictions on the validation set.\n",
    "\n",
    "3. Calculate and print the percentage of correct and incorrect predictions.\n",
    "\n",
    "4. Calculate and print the percentage of correct predictions for the class of interest (class 0).\n",
    "\n",
    "**Hint: Use the `train_test_split` from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html to split the data. For consistency, include `random_state=1` in the `train_test_split` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589af1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fecce3b4",
    "outputId": "7d4b4d20-f414-44c7-d011-f7a5d80f0a78",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ANSWER ###\n",
    "\n",
    "data = np.concatenate([X, np.expand_dims(y, axis=1)], axis=1)\n",
    "train, validation = sklearn.model_selection.train_test_split(data, test_size= 0.5, shuffle=True, random_state=1)\n",
    "predictions = train_and_predict(train, validation)\n",
    "validation_ys = validation[:, 2]\n",
    "print('% correct predictions:', (validation_ys == predictions).sum()/len(validation_ys))\n",
    "print('% incorrect predictions:', (validation_ys != predictions).sum()/len(validation_ys))\n",
    "\n",
    "indices = np.where(validation_ys == 0)\n",
    "\n",
    "print('% correct predictions on class of interest:', (validation_ys[indices] ==\n",
    "                                                      predictions[indices]).sum()\n",
    "      /len(validation_ys[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075425cb",
   "metadata": {
    "id": "68626adc"
   },
   "source": [
    "## Part two\n",
    "\n",
    "Now you’ll repeat the process but this time using oversampling to focus more on the class of interest.\n",
    "\n",
    "Note: Oversampling is manual in this example case (not using a library such as SMOTE, but rather balancing classes manually by yourself using random sampling).\n",
    "\n",
    "### To do: ###\n",
    "1. Split the data into two groups (strata):\n",
    "    - Set A: all samples of the class of interest\n",
    "    - Set B: all remaining samples\n",
    "\n",
    "2. Create the training set:\n",
    "    - Randomly select 50 per cent of the samples from set A.\n",
    "    - Add an equal number of randomly selected samples from set B.\n",
    "\n",
    "3. Create the validation set:\n",
    "    - Use the remaining 50 per cent of samples from set A.\n",
    "    - Add enough samples from set B to restore the original class ratio from the full data set.\n",
    "\n",
    "**Hint**: Use the `train_test_split` function from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html to divide the data. For consistency, include `random_state=1` in the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767193b9",
   "metadata": {
    "id": "c197190b"
   },
   "outputs": [],
   "source": [
    "### ANSWER ###\n",
    "\n",
    "set_a = np.concatenate([X, np.expand_dims(y, axis=1)], axis=1)[np.where(y==0)]\n",
    "set_b = np.concatenate([X, np.expand_dims(y, axis=1)], axis=1)[np.where(y!=0)]\n",
    "\n",
    "# Randomly select 50 per cent of the training samples from set A\n",
    "\n",
    "set_a_train, set_a_validation = train_test_split(set_a,test_size=0.5, shuffle=True, random_state=1)\n",
    "set_b_train, set_b_validation = train_test_split(set_b,test_size= 1-len(set_a_train)/len(set_b), shuffle=True, random_state=1)\n",
    "train = np.concatenate([set_a_train, set_b_train])\n",
    "validation = np.concatenate([set_a_validation, set_b_validation[:int((len(set_a_validation)* len(set_b))/len(set_a)), :]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c913b66",
   "metadata": {
    "id": "f63509c3"
   },
   "source": [
    "In the cell below, write code to check that the ratio of set A to set B in the validation set matches the original class ratio in the full data set. This ensures the validation set reflects the original class distribution accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df6088",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dc02bee",
    "outputId": "a2947367-dda7-45ff-83d3-8cdb3cd3a1d4"
   },
   "outputs": [],
   "source": [
    "print(len(set_a_validation)/len(set_b_validation[:int((len(set_a_validation) * len(set_b))/len(set_a)), :]))\n",
    "print(len(set_a)/len(set_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19fb5f",
   "metadata": {
    "id": "7f5be84f"
   },
   "source": [
    "## Part three\n",
    "\n",
    "For the oversampling method:\n",
    "\n",
    "1. Calculate and report the overall accuracy of the model’s predictions on the validation dataset.\n",
    "\n",
    "- This means calculating the percentage of all predictions that are correct out of the total number of samples in the validation set.\n",
    "\n",
    "- In addition, calculate and report the percentage of incorrect predictions as a complementary metric.\n",
    "\n",
    "2. Calculate and report the accuracy specifically for the class of interest (class label 0) in the validation data set.\n",
    "\n",
    "- Identify the samples that belong to the class of interest.\n",
    "\n",
    "- Compute the percentage of these samples for which the model’s predictions match the true labels.\n",
    "\n",
    "- This highlights the model’s performance on the specific class, which can be especially useful if it's an imbalanced data set or the class of interest is more critical to assess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746e9b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "086f9e16",
    "outputId": "feb27114-fef8-45ff-95b4-241c37fa12ea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ANSWER ###\n",
    "\n",
    "predictions = train_and_predict(train, validation)\n",
    "validation_ys = validation[:, 2]\n",
    "print('% correct predictions:', (validation_ys == predictions).sum()/len(validation_ys))\n",
    "print('% incorrect predictions:', (validation_ys != predictions).sum()/len(validation_ys))\n",
    "\n",
    "indices = np.where(validation_ys == 0)\n",
    "\n",
    "print('% correct predictions on class of interest:', (validation_ys[indices] ==\n",
    "                                                      predictions[indices]).sum()\n",
    "      /len(validation_ys[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513c207",
   "metadata": {
    "id": "404544f9"
   },
   "source": [
    "### To do: ###\n",
    "\n",
    "Answer the following questions in a markdown cell:\n",
    "\n",
    "1. What effect did oversampling have on the accuracy of prediction for the class of interest?\n",
    "\n",
    "2. What effect did oversampling have on the overall predictive accuracy for all classes?\n",
    "\n",
    "3. When might this trade-off be acceptable or even preferred?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceeedcb",
   "metadata": {
    "id": "2b44a038"
   },
   "source": [
    "### Answer: ###\n",
    "\n",
    "1. Oversampling dramatically increased the accuracy of prediction for the class of interest.\n",
    "\n",
    "2. Oversampling decreased the total correct predictions.\n",
    "\n",
    "3. This trade-off might be acceptable when the under-represented class is the one you care most about, such as in the case of fraud or cancer detection, even if it means misclassifying more cases from the other classes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
