{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uq4YDXHCqzlC",
   "metadata": {
    "id": "uq4YDXHCqzlC"
   },
   "source": [
    "# Self-study try-it activity 7.2: Implementing k-fold cross-validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb14de-9bc1-44ba-80b0-c5005064619c",
   "metadata": {},
   "source": [
    "##### This notebook is divided into two parts:\n",
    "\n",
    "- Part one guides you through a manual implementation of k-fold cross-validation.\n",
    "\n",
    "- Part two demonstrates how to achieve the same using built-in tools from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d6df2",
   "metadata": {
    "id": "880d6df2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_diabetes,load_iris\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d996d",
   "metadata": {
    "id": "824d996d"
   },
   "source": [
    "## Part one: Implementing a manual approach to k-fold cross-validation\n",
    "\n",
    "### k-fold cross validation with kernel ridge regression (KRR)\n",
    "\n",
    "In this section, you will implement k-fold cross-validation using a kernel ridge regression (KRR) model. You are provided with the pre-defined `fit_and_predict` functions to generate model predictions.\n",
    "\n",
    "The primary goal of this exercise is to practise implementing k-fold cross-validation. The section is structured into five tasks:\n",
    "\n",
    "1. Create a function to split the data into k folds.\n",
    "\n",
    "2. Develop a performance metric function using RMSE.\n",
    "\n",
    "3. Write a function to run cross-validation on the k-folds.\n",
    "\n",
    "4. Run cross validation for k={2, ..., 100}, measuring the execution time of each.\n",
    "\n",
    "5. Answer the questions in a markdown cell.\n",
    "\n",
    "**Note:** All required Python packages have already been imported for you in this notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576c905",
   "metadata": {
    "id": "0576c905"
   },
   "source": [
    "## Data\n",
    "\n",
    "The `load_diabetes` data set from `scikit-learn` is a regression data set that contains medical data from 442 diabetes patients. It includes ten baseline clinical features, such as age, sex, body mass index (BMI), average blood pressure and six blood serum measurements. The target variable represents a quantitative measure of disease progression one year after the baseline. This data set is commonly used for regression tasks, particularly for predicting diabetes progression based on clinical input variables.\n",
    "\n",
    "You can find more details about the data set here: https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801d79b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d801d79b",
    "outputId": "81067442-844a-48f4-c8c0-1fc8a8f3fba8"
   },
   "outputs": [],
   "source": [
    "#Do not edit this cell\n",
    "\n",
    "X_, y_ = load_diabetes(return_X_y=True)\n",
    "\n",
    "#Standardise the data to help you fit the data (this will be covered later in the programme)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_)\n",
    "X = scaler.transform(X_)[:300, :]\n",
    "\n",
    "scaler_y = preprocessing.StandardScaler().fit(y_.reshape(-1, 1))\n",
    "y = scaler_y.transform(y_.reshape(-1, 1))[:300, :]\n",
    "print(y.shape)\n",
    "\n",
    "#To ensure the data stays in the correct order, you will work with data frames\n",
    "\n",
    "columns = [f'x_{i}' for i in range(X.shape[1])] + ['y']\n",
    "x_columns = [f'x_{i}' for i in range(X.shape[1])]\n",
    "data = pd.DataFrame(data= np.concatenate([X, y.reshape(-1, 1)], axis=1), columns=columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zPe3H8tkrTZT",
   "metadata": {
    "id": "zPe3H8tkrTZT"
   },
   "source": [
    "### Kernel ridge regression (KRR)\n",
    "\n",
    "KRR is a regression method that extends simple linear regression to handle non-linear data by using kernels. It applies ridge regularisation to manage model complexity and prevent overfitting. In this case, the model uses the `RBF kernel` (radial basis function) with `gamma=0.1`to transform the input data into a higher-dimensional space where a linear model can be fitted more effectively to capture non-linear patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c61cc",
   "metadata": {
    "id": "3d2c61cc"
   },
   "outputs": [],
   "source": [
    "#Do not edit\n",
    "\n",
    "def fit_and_predict_KRR(train, validate):\n",
    "    \"\"\"fit a Kernel Ridge Regression Model on the training data and predict the y values of the validation X data.\n",
    "    :param train: pandas dataframe containing the training data\n",
    "    :param validate: pandas dataframe containing the validation data\n",
    "    :return: predictions at the validation X points Mx1 numpy array\"\"\"\n",
    "    X_train = train[x_columns].to_numpy()\n",
    "    y_train = train['y'].to_numpy()\n",
    "    X_val = validate[x_columns].to_numpy()\n",
    "\n",
    "    KRR = KernelRidge(alpha=0.1, kernel='rbf', gamma=0.2,  degree=100)\n",
    "    KRR.fit(X_train, y_train)\n",
    "    return KRR.predict(X_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a77092a",
   "metadata": {
    "id": "5a77092a"
   },
   "source": [
    "### To-Do: Create a function to split data into k folds\n",
    "\n",
    "- Fill in the gaps to create a function that split the data into k folds. \n",
    "\n",
    "- Assign the results to `len_folds`. \n",
    "\n",
    "Hint: Use `np.array_split()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855e2b5",
   "metadata": {
    "id": "8855e2b5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def k_folds(data, k):\n",
    "    \"\"\"function that returns a list of k folds of the data\"\"\"\n",
    "\n",
    "    ############################\n",
    "    #Create list of how long each fold should be. The folds should be as even as possible in number, but they\n",
    "    #need to have an extra data point if the total number of data points isn't divisible by n.\n",
    "    len_folds = [int(sum(x)) for x in np.array_split(np.ones(len(data)), k)]\n",
    "    ############################\n",
    "\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        data_ss = data.sample(n=len_folds[i], random_state=20)\n",
    "        data = data.drop(data_ss.index)\n",
    "        folds.append(data_ss)\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da640be",
   "metadata": {
    "id": "3da640be"
   },
   "source": [
    "### To-Do: Develop a performance metric function using RMSE\n",
    "\n",
    "Define the function to compute the RMSE between the predicted and actual target (y) values. Both inputs must be `NumPy arrays` and the function returns a single float. RMSE is calculated as the square root of the mean of the squared differences between predicted values and the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fea12c",
   "metadata": {
    "id": "c9fea12c"
   },
   "outputs": [],
   "source": [
    "def rmse(prediction, true):\n",
    "    return np.sqrt(np.mean(np.square(prediction-true)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127862b",
   "metadata": {
    "id": "3127862b"
   },
   "source": [
    "### To-Do: Write a function to run cross-validation on the k-folds\n",
    "\n",
    "Use the function `cross-validation(folds)` to run the cross-validation on both of the models. This functions returns the average RMSE for the KRR model.\n",
    "\n",
    "Hint: To create the training sets, use the concatenation on `(folds[:i]+folds[(i+1):])`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896eb1d5",
   "metadata": {
    "id": "896eb1d5"
   },
   "outputs": [],
   "source": [
    "def cross_validation(folds):\n",
    "    folds = copy.copy(folds) #This creates a new variable, which is a copy of folds\n",
    "\n",
    "    rmses_KRR = []  #This is a list to collect the RMSEs for each fold for the KRR\n",
    "\n",
    "    for i, fold in enumerate(folds):\n",
    "\n",
    "        ############################\n",
    "        #Write code to create the training and validation sets as data frames\n",
    "\n",
    "        train = pd.concat(folds[:i]+folds[(i+1):])\n",
    "#         train = pd.concat([folds.pop(i)])\n",
    "        validate = fold\n",
    "\n",
    "        ############################\n",
    "\n",
    "        ############################\n",
    "        #Use the fit_and_predict function to create new columns in the validation set for the predictions\n",
    "        #for KRR model with the heading ['KRR_predictions'].\n",
    "\n",
    "        validate['KRR_predictions'] = fit_and_predict_KRR(train, validate)\n",
    "\n",
    "        ############################\n",
    "\n",
    "        ############################\n",
    "        #Calculate the RMSE and append it to rmses_KRR\n",
    "\n",
    "        rmses_KRR.append(rmse(validate['KRR_predictions'].to_numpy(), validate['y'].to_numpy()))\n",
    "\n",
    "        ############################\n",
    "\n",
    "    RMSE_KRR = np.mean(rmses_KRR) # calculate the average RMSEs for kernel ridge regression\n",
    "\n",
    "    return RMSE_KRR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0461fd",
   "metadata": {
    "id": "3b0461fd"
   },
   "source": [
    "\n",
    "For k = 100, calculate the RMSE for the KRR model and print the solution.\n",
    "\n",
    "Hint: Use `cross_validation(copy.copy(folds))` and assign it to RMSE_KRR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abea7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90abea7c",
    "outputId": "18ca41a4-403b-4aeb-e9c4-5c5d378ea64d"
   },
   "outputs": [],
   "source": [
    "folds =  k_folds(data, 100)\n",
    "print(len(folds))\n",
    "RMSE_KRR = cross_validation(copy.copy(folds))\n",
    "print(RMSE_KRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f749dfb",
   "metadata": {
    "id": "6f749dfb"
   },
   "source": [
    "### To-Do: Run cross-validation for different values of k\n",
    "\n",
    "- For k={2, ..., 100}, split the data into k folds and run the cross-validation. \n",
    "\n",
    "- Save the results from each run in a list. Then, create a plot with k values on the x-axis and RMSE on the y-axis.\n",
    "\n",
    "- Use the time function (see the example below) to measure how long the cross-validation takes for each value of k. Plot the time against the value of k.\n",
    "\n",
    "**Try the following values of k: 5, 7, 10, 50, and 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136f2e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4136f2e8",
    "outputId": "f4180f41-7026-4ee7-c61a-4c14ab571793",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here is a time function example\n",
    "\n",
    "start = time.time()\n",
    "print('hello')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55cb86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944
    },
    "id": "ad55cb86",
    "outputId": "70f4c0d2-2d58-4502-e5d1-910f30b06cb8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K=5\n",
    "KRRs = []\n",
    "\n",
    "times = []\n",
    "for k in range(2, K):\n",
    "    start = time.time()\n",
    "    folds = k_folds(data, k)\n",
    "    RMSE_KRR = cross_validation(folds)\n",
    "    end = time.time()\n",
    "    KRRs.append(RMSE_KRR)\n",
    "\n",
    "    times.append(end - start)\n",
    "\n",
    "\n",
    "plt.plot(list(range(2,K)), KRRs, label='KRR')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('RMSEs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('k')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(list(range(2,K)), times)\n",
    "plt.title('time to compute')\n",
    "plt.ylabel('time (s)')\n",
    "plt.xlabel('k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf2f8",
   "metadata": {
    "id": "9e2cf2f8"
   },
   "source": [
    "### To-Do: Answer the question\n",
    "\n",
    "Answer the following question in a markdown cell:\n",
    "\n",
    "Repeat the above code for k values of 5, 10, 50 and 100 and note the RMSEs and the times taken. Looking at the plots you made, what are the benefits and drawbacks of increasing k?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ef61e",
   "metadata": {
    "id": "882ef61e"
   },
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f429d42-ba75-48c8-bbef-a02474b064db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here:\n",
    "# As k increases, you get more consistent results, which is good for reproducibility. However, this is at the cost of computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SrBGR2fDfTHp",
   "metadata": {
    "id": "SrBGR2fDfTHp"
   },
   "source": [
    "## Part two: Using `sklearn` for k-fold cross-validation \n",
    "\n",
    "### To-Do: Using `sklearn` for k-fold cross-validation with a `LogisticRegression` classifier\n",
    "\n",
    "Here, the `Iris` data set, a toy data set provided by `sklearn`, is used for a classification task. The accuracy score used comes from cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e246ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04e246ac",
    "outputId": "1963cbcc-4131-4619-f617-6d21e88ae199"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Load the Iris data set (classification)\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "#Define a logistic regression model\n",
    "model = LogisticRegression(max_iter=200, random_state=42)\n",
    "\n",
    "#Define five-fold cross-validation with shuffle for randomness\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Evaluate the model using cross-validation (default scoring is accuracy for classification)\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "print(\"Cross-Validation accuracy scores:\", scores)\n",
    "print(\"Average CV accuracy score:\", np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iXMLI4bClba-",
   "metadata": {
    "id": "iXMLI4bClba-"
   },
   "source": [
    "### To-Do: Using `sklearn` for k-fold cross-validation for regression\n",
    "\n",
    "\n",
    "- Use the `load_diabetes` data set and the following model: `model = KernelRidge(alpha=0.1, kernel='rbf', gamma=1.0)`.\n",
    "- Apply k-fold cross-validation with five splits and compute the average cross-validation score.\n",
    "\n",
    "Note: You can use any of the regression metrics, such as MAE, MSE, $R^2$ or RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc09b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0bc09b4",
    "outputId": "e1a001ef-5dd3-4afc-9b01-2666c5669db1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Load the Diabetes data set (regression)\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "#Define the KRR model with RBF kernel\n",
    "model = KernelRidge(alpha=0.1, kernel='rbf', gamma=1.0)\n",
    "\n",
    "#Define five-fold cross-validation with shuffle for randomness\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Evaluate the model using cross-validation (default scoring is R² for regression)\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "print(\"Cross-Validation R² scores:\", scores)\n",
    "print(\"Average CV R² score:\", np.mean(scores))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
