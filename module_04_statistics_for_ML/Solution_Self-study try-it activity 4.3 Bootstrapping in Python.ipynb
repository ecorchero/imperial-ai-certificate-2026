{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "G8X7m6bY863U",
   "metadata": {
    "id": "G8X7m6bY863U"
   },
   "source": [
    "# Self-study try-it activity 4.3: Bootstrapping in Python\n",
    "\n",
    "Bootstrapping is a resampling technique used to create multiple training data sets by sampling the original data set with replacement. Each bootstrapped data set is of the same size as the original, but it may include duplicate observations while leaving others out. This method is widely used to estimate model stability, reduce overfitting and improve robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pOoqpEp4-Vw9",
   "metadata": {
    "id": "pOoqpEp4-Vw9"
   },
   "source": [
    "## How bootstrapping works:\n",
    "\n",
    "- Sampling with replacement: randomly draw data points from the original data set, allowing duplicates.\n",
    "\n",
    "- Training multiple models: use each bootstrapped sample to train a separate model.\n",
    "\n",
    "- Aggregating predictions: combine predictions from all models, typically through averaging (for regression) or majority voting (for classification), to improve accuracy and reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96505bfb",
   "metadata": {
    "id": "96505bfb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.stats import multivariate_normal\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EltEnEaV_yH0",
   "metadata": {
    "id": "EltEnEaV_yH0"
   },
   "source": [
    "Generate a data set of 1,000 students with a mean height of 170 and standard deviation of 10. Perform bootstrapping and compute the new means and the `confidence_interval`, assuming a 95 per cent confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f8c1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c5f8c1c",
    "outputId": "492c3ba5-1238-43db-ce88-325e5f95e3b3"
   },
   "outputs": [],
   "source": [
    "#Generate a data set (e.g. heights of students)\n",
    "data = np.random.normal(loc=170, scale=10, size=1000)  #Mean = 170, StdDev = 10, size = 1000\n",
    "\n",
    "#Number of bootstrap samples\n",
    "n_bootstrap_samples = 1000\n",
    "\n",
    "#Store means of bootstrap samples\n",
    "bootstrap_means = []\n",
    "\n",
    "#Perform bootstrapping\n",
    "for _ in range(n_bootstrap_samples):\n",
    "    #Sample with replacement from the original data\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    #Calculate the mean of the bootstrap sample\n",
    "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "#Calculate the overall mean and confidence interval\n",
    "mean_estimate = np.mean(bootstrap_means)\n",
    "confidence_interval = (np.percentile(bootstrap_means, 2.5), np.percentile(bootstrap_means, 97.5))\n",
    "\n",
    "print(f\"Estimated Mean: {mean_estimate}\")\n",
    "print(f\"95% Confidence Interval: {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180de55e",
   "metadata": {
    "id": "180de55e"
   },
   "source": [
    "## Examples of bootstrapping\n",
    "\n",
    "These examples are inspired by James, Gareth, Daniela Witten, Trevor Hastie, and Rob Tibshirani. *An introduction to statistical learning.* Springer, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d955a",
   "metadata": {
    "id": "899d955a"
   },
   "source": [
    "### Motivation\n",
    "\n",
    "Let's review two different stocks: $X$ and $Y$, normally distributed with the same mean of $\\mu_X := \\mathbb{E}[X] = 2$ and $\\mu_Y := \\mathbb{E}[Y] = 2$. \n",
    "\n",
    "Additionally, $\\sigma^2_X := \\mathbb{V}\\mathrm{AR}[X] = 1$, $\\sigma^2_Y := \\mathbb{V}\\mathrm{AR}[Y] = 1.25$, and $\\sigma_{XY} := \\mathbb{C}\\mathrm{OV}[X,Y] = 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YS3SKskdAffe",
   "metadata": {
    "id": "YS3SKskdAffe"
   },
   "source": [
    "### Question 1: How can you sample $1,000$ returns from these stocks?\n",
    "\n",
    "**Answer 1:** The function `np.random.multivariate_normal(mu, r, size=n)` generates random samples from a multivariate normal (Gaussian) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516980f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0516980f",
    "outputId": "e4a05b10-1c18-4a1b-a8a7-6c44e2b55e9b"
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "#Vector of means\n",
    "mu = np.array([2 ,2])\n",
    "\n",
    "#Describe covariance matrix\n",
    "r = np.array([\n",
    "        [  1,    0.5],\n",
    "        [ 0.5,  1.25]\n",
    "    ])\n",
    "\n",
    "#Generate the random samples\n",
    "returns = np.random.multivariate_normal(mu, r, size=n)\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f97a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "18f97a79",
    "outputId": "c9d22c9a-ca91-490d-df8a-26672502e2d5"
   },
   "outputs": [],
   "source": [
    "# Plot the returns\n",
    "x = returns[:,0]\n",
    "y = returns[:,1]\n",
    "x1, y1 = [-1, 5.5], [-1, 5.5]\n",
    "plt.plot(x1, y1, c = \"r\", alpha= .3)\n",
    "plt.title(r\"Returns of stocks $X$ and $Y$, points below the red line are the cases where $X$ has a larger return\")\n",
    "plt.xlabel(r\"$X$\")\n",
    "plt.ylabel(r\"$Y$\")\n",
    "plt.scatter(x,y,s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb43f01",
   "metadata": {
    "id": "2fb43f01"
   },
   "source": [
    "### Question 2: How can you find an optimal $\\alpha^\\star$?\n",
    "\n",
    "Let's invest in two stocks: $X$ and $Y$. Allocate a portion $\\alpha \\in [0,1]$ of your money to stock $X$ and the remaining $1 - \\alpha$ to stock $Y$. The goal is to minimise the risk of this investment, where risk is measured by the variance of the portfolio return.\n",
    "\n",
    "In other words, you need to solve:\n",
    "\n",
    "$\\alpha^\\star \\in \\arg\\min_{\\alpha} \\{ \\mathbb{V}\\mathrm{AR}[\\alpha X + (1-\\alpha)Y] \\}$\n",
    "\n",
    "How can you find an optimal $\\alpha^\\star$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e479f05",
   "metadata": {
    "id": "0e479f05"
   },
   "source": [
    "**Answer 2:** Recall that\n",
    "\n",
    "\\begin{align*} \\mathbb{V}\\mathrm{AR}[\\alpha X + (1-\\alpha)Y] &= \\alpha^2 \\mathbb{V}\\mathrm{AR}[X] + (1-\\alpha)^2 \\mathbb{V}\\mathrm{AR}[Y] + 2\\alpha(1-\\alpha) \\mathbb{C}\\mathrm{OV}[X,Y]\\\\\n",
    "& = \\alpha^2 \\sigma^2_X + (1-\\alpha)^2 \\sigma^2_Y + 2\\alpha(1-\\alpha) \\sigma_{XY}\n",
    "\\end{align*}\n",
    "\n",
    "Let's minimise this function by plugging in the true values of $\\sigma_X^2 = 1,\\  \\sigma_Y^2 = 1.25, \\ \\sigma_{XY} = 0.5$, using the ```scipy optimize``` function. \n",
    "\n",
    "Note: `round(float(solution.x), 3)` is used. This extracts the scalar solution from the single-value array returned by the optimizer and rounds it to three decimal places for cleaner, more readable output.\n",
    "\n",
    "When plugging these values, the problem is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{array}{ll}\n",
    "\\text{minimise}_\\alpha & (1-\\alpha)^2 \\times 1.25 + \\alpha \\\\\n",
    "\\text{subject to} & \\alpha \\in [0,1].\n",
    "\\end{array}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1a570",
   "metadata": {
    "id": "f6d1a570"
   },
   "outputs": [],
   "source": [
    "def objective_given(alpha):\n",
    "    \"\"\"The objective function to minimize\"\"\"\n",
    "    return (1-alpha)**2 * 1.25 + alpha\n",
    "bounds = optimize.Bounds([0],[1])\n",
    "solution = optimize.minimize(objective_given, x0 = [0], bounds = bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb3982",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3acb3982",
    "outputId": "e7160c72-a879-4400-e735-a638ac5d2868"
   },
   "outputs": [],
   "source": [
    "print(\"The optimal solution is when alpha = \", round(float(solution.x),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed07569",
   "metadata": {
    "id": "5ed07569"
   },
   "source": [
    "What happens if you keep $\\sigma^2_X, \\sigma^2_Y, \\sigma_{XY}$ as parameters and change them whenever you want? \n",
    "\n",
    "In other words, you need to solve:\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{array}{ll}\n",
    "\\text{minimise}_\\alpha & \\alpha^2 \\sigma^2_X + (1-\\alpha)^2 \\sigma^2_Y + 2\\alpha(1-\\alpha) \\sigma_{XY} \\\\\n",
    "\\text{subject to} & \\alpha \\in [0,1].\n",
    "\\end{array}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1583e7",
   "metadata": {
    "id": "ac1583e7"
   },
   "outputs": [],
   "source": [
    "def objective_given(alpha, varx, vary, covar):\n",
    "    \"\"\"The objective function to minimize\"\"\"\n",
    "    return (alpha**2 * varx) + ((1-alpha)**2 * vary) + (2*alpha*(1-alpha)*covar)\n",
    "bounds = optimize.Bounds([0],[1])\n",
    "solution = optimize.minimize(objective_given, x0 = [0], bounds = bounds, args=(1,1.25,0.5)) #this was previous case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2674b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2674b0a",
    "outputId": "49927688-2012-4734-a934-a96a17ec5891"
   },
   "outputs": [],
   "source": [
    "print(\"The optimal solution is when alpha = \", round(float(solution.x),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6a58e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fab6a58e",
    "outputId": "9ed911e1-bfd5-4f1f-bf35-0ad656f64d55"
   },
   "outputs": [],
   "source": [
    "solution = optimize.minimize(objective_given, x0 = [0], bounds = bounds, args=(5,1.25,0.5))\n",
    "print(\"The optimal solution is when alpha = \", round(float(solution.x),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1243e0",
   "metadata": {
    "id": "2b1243e0"
   },
   "source": [
    "You can see that the larger $\\sigma^2_X$ gets, the less you invest in $X$ as $\\alpha$ decreases. As $\\sigma^2_X$ goes up, meaning the riskier the asset, the less we invest in it to keep the portfolio balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37fb8b",
   "metadata": {
    "id": "aa37fb8b"
   },
   "source": [
    "A common mistake in optimisation practice is over-relying on solvers when, in many cases, the solution can be derived analytically. Doing so has a key advantage: the structure of the optimal solution becomes explicitly parametrised by \n",
    "$\\sigma_X^2, \\ \\sigma_Y^2, \\ \\sigma_{XY}$. This not only simplifies computation but also gives deeper intuition into the investment strategy.\n",
    "\n",
    "Letâ€™s walk through how that works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8098e0",
   "metadata": {
    "id": "0b8098e0"
   },
   "source": [
    "The objective function can be rewritten as:\n",
    "\n",
    "\\begin{align*} \\mathbb{V}\\mathrm{AR}[\\alpha X + (1-\\alpha)Y] &= \\alpha^2 \\sigma^2_X + (1-\\alpha)^2 \\sigma^2_Y + 2\\alpha(1-\\alpha) \\sigma_{XY} \\\\\n",
    "& = \\alpha^2 \\sigma^2_X + \\sigma^2_Y + \\alpha^2 \\sigma^2 Y - 2\\alpha \\sigma^2_Y + 2\\alpha \\sigma_{XY} - 2\\alpha^2 \\sigma_{XY} \\\\\n",
    "& = \\alpha^2(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) + 2\\alpha(\\sigma_{XY} - \\sigma^2_Y) + \\sigma_Y^2\n",
    "\\end{align*}\n",
    "\n",
    "Notice that this is a quadratic function of $\\alpha$, and the coefficient of $\\alpha^2$ is $\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}$, which is $\\mathbb{V}\\mathrm{AR}[X - Y] \\geq 0$. Hence, $\\alpha^2$ has a coefficient term, concluding the objective function is **convex**. So, if you take the first-order conditions, then the solution that solves them is optimal. In other words:\n",
    "\n",
    "\\begin{align*}\n",
    "\\dfrac{\\mathrm{d}\\left[ \\alpha^2(\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) + 2\\alpha(\\sigma_{XY} - \\sigma^2_Y) + \\sigma_Y^2 \\right]}{\\mathrm{d} \\alpha} = 2\\alpha (\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}) + 2(\\sigma_{XY} - \\sigma^2_Y)\n",
    "\\end{align*}\n",
    "\n",
    "Optimal $\\alpha^\\star$ sets the above expression equal to zero; hence, it immediately follows that:\n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha^\\star = \\dfrac{\\sigma^2_Y - \\sigma_{XY}}{\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}}.\n",
    "\\end{align*}\n",
    "\n",
    "Let's test whether this is correct now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4c0a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27c4c0a1",
    "outputId": "334f87cd-3d24-4c57-c9a0-4dbe8199d9f8"
   },
   "outputs": [],
   "source": [
    "def optimal_alpha(varx, vary, covar):\n",
    "    return (float) (vary - covar)/(varx + vary - 2*covar)\n",
    "round(optimal_alpha(1, 1.25, 0.5),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10b70f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb10b70f",
    "outputId": "5cb1535d-2291-4280-d95f-91d5b3893c38"
   },
   "outputs": [],
   "source": [
    "round(optimal_alpha(5, 1.25, 0.5),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8852526",
   "metadata": {
    "id": "d8852526"
   },
   "source": [
    "### Question 3: How can you decide the optimal investment strategy for the future by looking at the **past data**?\n",
    "\n",
    "\n",
    "In real life, you **never** know the distribution of stocks $X$ and $Y$. Hence, you can only **estimate** $\\sigma^2_X, \\ \\sigma^2_Y, \\ \\sigma_{XY}$ from a sample of $(X,Y)$ realisations. \n",
    "\n",
    "Let's have $n$ samples of $(X,Y)$ and name them $(X_i, Y_i)$ for $i=1,\\ldots,n$. \n",
    "\n",
    "How can you decide the optimal investment strategy for the future by looking at the **past data**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50fea29",
   "metadata": {
    "id": "b50fea29"
   },
   "source": [
    "**Answer 3:** Use the sample provided to estimate $\\sigma_X^2$, $\\sigma_Y^2$, $\\sigma_{XY}$. Let these estimates be $\\hat{\\sigma}_X^2, \\ \\hat{\\sigma}_Y^2, \\ \\hat{\\sigma}_{XY}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6aef32",
   "metadata": {
    "id": "9f6aef32"
   },
   "source": [
    "#### Step 1: Estimate the mean returns $\\bar{X} and \\ \\bar{Y}$ by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{X} &= \\frac{1}{n}\\sum_{i=1}^n X_i \\\\\n",
    "\\bar{Y} &= \\frac{1}{n}\\sum_{i=1}^n Y_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6b0de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69d6b0de",
    "outputId": "b97a74cb-5799-451b-e059-8911fde92cbd"
   },
   "outputs": [],
   "source": [
    "hat_mean = np.mean(returns,0)\n",
    "print(hat_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace89d9d",
   "metadata": {
    "id": "ace89d9d"
   },
   "source": [
    "#### Step 2: Estimate the covariance matrix by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "\\hat{\\sigma}^2_X & \\hat{\\sigma}_{XY} \\\\\n",
    "\\hat{\\sigma}_{XY} & \\hat{\\sigma}^2_Y\n",
    "\\end{bmatrix} = \\dfrac{1}{n-1} \\sum_{i=1}^n \\left( \\begin{bmatrix} X_i & Y_i \\end{bmatrix}^\\top \\begin{bmatrix} X_i & Y_i \\end{bmatrix} \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45836a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a45836a2",
    "outputId": "6d19515d-2453-4543-df5f-7651a3778cdd"
   },
   "outputs": [],
   "source": [
    "hat_cov = np.zeros((2,2))\n",
    "for i in range(n):\n",
    "    hat_cov = hat_cov + (returns[i]-hat_mean).reshape((2,1))*(returns[i]-hat_mean).reshape((1,2))\n",
    "hat_cov = hat_cov/(n-1)\n",
    "hat_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ab696",
   "metadata": {
    "id": "907ab696"
   },
   "outputs": [],
   "source": [
    "hat_varx = hat_cov[0,0]\n",
    "hat_vary = hat_cov[1,1]\n",
    "hat_covar = hat_cov[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d927bb",
   "metadata": {
    "id": "21d927bb"
   },
   "source": [
    "#### Step 3: Estimate $\\alpha^\\star$ by:\n",
    "\\begin{align*}\n",
    "\\hat{\\alpha}^\\star = \\dfrac{\\hat{\\sigma}^2_Y - \\hat{\\sigma}_{XY}}{\\hat{\\sigma}^2_X + \\hat{\\sigma}^2_Y - 2\\hat{\\sigma}_{XY}}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279180fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "279180fa",
    "outputId": "1a016e73-1d9d-4dbc-f0f2-dd54a89bbbe8"
   },
   "outputs": [],
   "source": [
    "round(optimal_alpha(hat_varx, hat_vary, hat_covar),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d48087",
   "metadata": {
    "id": "16d48087"
   },
   "source": [
    "The real optimal strategy (if you really knew the distribution behind $(X, Y)$) would be $\\alpha^\\star = 0.6$. However, as you see $1,000$ samples, you can estimate $0.629$. Let's make a function that generalises this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df173cf",
   "metadata": {
    "id": "7df173cf"
   },
   "outputs": [],
   "source": [
    "def generate_sample(n, varx=1, vary=1.25, covar=0.5): #Generate a sample of n returns\n",
    "    mu = np.array([2 ,2])\n",
    "    r = np.array([\n",
    "            [  varx, covar],\n",
    "            [ covar,  vary]])\n",
    "    sample_returns = np.random.multivariate_normal(mu, r, size=n)\n",
    "    return sample_returns\n",
    "def hat_alpha(sample_returns): #Estimate the optimal investment strategy\n",
    "    hat_mean = np.mean(sample_returns,0)\n",
    "    hat_cov = np.zeros((2,2))\n",
    "    n = np.size(sample_returns,0)\n",
    "    for i in range(n):\n",
    "        hat_cov = hat_cov + (sample_returns[i]-hat_mean).reshape((2,1))*(sample_returns[i]-hat_mean).reshape((1,2))\n",
    "    hat_cov = hat_cov/(n-1)\n",
    "    hat_varx = hat_cov[0,0]\n",
    "    hat_vary = hat_cov[1,1]\n",
    "    hat_covar = hat_cov[0,1]\n",
    "    return round(optimal_alpha(hat_varx, hat_vary, hat_covar),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf5a46",
   "metadata": {
    "id": "7ebf5a46"
   },
   "source": [
    "### Question 4: How does the estimation change with different samples? Can it be that the estimation $\\hat{\\alpha}^\\star$ is very different from the real $\\alpha$ (which you don't see), but the specific sample of returns has a huge bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007d2f4",
   "metadata": {
    "id": "6007d2f4"
   },
   "outputs": [],
   "source": [
    "simulation = 1000 #Number of times to simulate\n",
    "samples = 1000 #How many samples do you see in each 'scenario'?\n",
    "estimations = np.zeros(simulation)\n",
    "for sim in range(simulation):\n",
    "    estimations[sim] = hat_alpha(generate_sample(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83a258",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b83a258",
    "outputId": "95b81b80-bdfb-4cf7-a5bc-0fe9a4d8ae23"
   },
   "outputs": [],
   "source": [
    "print(\"mean\", round(np.mean(estimations),3),\"min\",np.min(estimations), \"max\", np.max(estimations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ffc7b",
   "metadata": {
    "id": "107ffc7b"
   },
   "source": [
    "**Answer 4:** As you can see, the mean of all estimations is equal to the true $\\alpha$, which is the result of the unbiased estimation. However, the estimation varies between $[0.528, 0.686]$. How often do you think you receive 'bad' values? Let's see in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66d377",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "2a66d377",
    "outputId": "5dc14057-28d8-4386-dfbc-392aaeabb641"
   },
   "outputs": [],
   "source": [
    "plt.hist(estimations,  bins = 20)  #Density=false would make counts\n",
    "plt.axvline(x=0.6, color='r', linestyle='--', label = r\"true value of $\\alpha^\\star$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b96c2",
   "metadata": {
    "id": "607b96c2"
   },
   "source": [
    "Previously, you had $1,000$ simulations, and in each simulation, you had $1,000$ samples. In real life, you rarely get such a big sample. What if you just have $100$ samples? Let's review the histogram again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59519f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d59519f",
    "outputId": "b5406e2e-8a5b-41ee-dbc6-5fc01ec50095"
   },
   "outputs": [],
   "source": [
    "samples = 100 #How many samples do you see in each 'scenario'?\n",
    "estimations = np.zeros(simulation)\n",
    "for sim in range(simulation):\n",
    "    estimations[sim] = hat_alpha(generate_sample(samples))\n",
    "print(\"mean\", round(np.mean(estimations),3),\"min\",np.min(estimations), \"max\", np.max(estimations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd249bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "5fd249bb",
    "outputId": "cee371ca-2f72-4e0d-c1c6-2d62d6fbf2dc"
   },
   "outputs": [],
   "source": [
    "plt.hist(estimations,  bins = 30, color = 'g')  #Density=false would make counts\n",
    "plt.axvline(x=0.6, color='r', linestyle='--', label = r\"true value of $\\alpha^\\star$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ffd71",
   "metadata": {
    "id": "4a3ffd71"
   },
   "source": [
    "### Question 5: In real life, you are in a single 'simulation'. As you don't know the real distribution of data, you cannot generate $1,000$ samples and decide accordingly. You need to take a risk and trust your $\\hat{\\alpha}^\\star$ estimation. The question is, can you quantify this 'trust'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72319b2",
   "metadata": {
    "id": "d72319b2"
   },
   "source": [
    "**Answer 5:** It turns out, you can! Bootstrapping saves you here. Let's see the simple statistics of the previous simulation. \n",
    "\n",
    "First, denote the previous simulations by $B = 1,\\ldots,1000$. Recall that in the very last experiment, in every simulation, you generated a sample of $100$ returns of $(X,Y)$. What is the mean of the estimations $\\hat{\\alpha}_b$ (where $b \\in \\{ 1,\\ldots, B\\}$ is the simulation number)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11015806",
   "metadata": {
    "id": "11015806"
   },
   "source": [
    "You can get that through $\\bar{\\alpha} = \\sum_{b=1}^B \\hat{\\alpha}_b$. Note that you need to drop the notation $\\alpha^\\star$, as it is clear that you are estimating the optimal $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc39cb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bc39cb7",
    "outputId": "6debeabb-d825-4c5c-a6cf-4e8499e24f8b"
   },
   "outputs": [],
   "source": [
    "B = simulation #Notational convenience\n",
    "bar_alpha = np.mean(estimations)\n",
    "round(bar_alpha,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1fc461",
   "metadata": {
    "id": "ef1fc461"
   },
   "source": [
    "Now, let's compute the standard deviation of these estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3bf68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbf3bf68",
    "outputId": "520f5c5f-d9e4-47b6-ad02-9a9831a76ddb"
   },
   "outputs": [],
   "source": [
    "standard_error = np.sqrt( np.sum(np.square(estimations - bar_alpha)) /(B-1))\n",
    "round(standard_error,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40a46b",
   "metadata": {
    "id": "5c40a46b"
   },
   "source": [
    "You now conclude that the estimation satisfies $SE(\\hat{\\alpha}) \\approx 0.081$ **based on the simulations**. So, if you randomly sample $100$ returns of $(X,Y)$ just once and estimate $\\hat{\\alpha}$ via the formula derived, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\alpha}^\\star = \\dfrac{\\hat{\\sigma}^2_Y - \\hat{\\sigma}_{XY}}{\\hat{\\sigma}^2_X + \\hat{\\sigma}^2_Y - 2\\hat{\\sigma}_{XY}}\n",
    "\\end{align*}\n",
    "\n",
    "then you can expect this number to deviate from the *true optimal* $\\alpha$, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha^\\star = \\dfrac{\\sigma^2_Y - \\sigma_{XY}}{\\sigma^2_X + \\sigma^2_Y - 2\\sigma_{XY}}\n",
    "\\end{align*}\n",
    "\n",
    "by an amount of $0.082$ on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0ff38",
   "metadata": {
    "id": "26a0ff38"
   },
   "source": [
    "However, in the above experiments, you simulated a sample of returns (of size $100$) for $1,000$ times. Such sampling requires the distribution of $(X,Y)$. Again, in real life, you do not know the true distribution. You only have a single sample of $100$ returns of $(X, Y)$, and that is all you know. Let's denote the sample as $\\mathcal{R} = \\{(X_i, Y_i) \\ : \\ i = 1,\\ldots,100 \\}$.\n",
    "\n",
    "So, how can you apply the previous simulation? \n",
    "\n",
    "Here comes bootstrapping. The idea is simple: as before, you simulate $1,000$ times, and in each simulation, you sample $100$ realisations of $(X,Y)$ returns. \n",
    "\n",
    "But this time, you use the returns $\\mathcal{R}$ you already have. However, if you sample $100$ distinct values, this is basically equivalent to the true set of returns you have. \n",
    "\n",
    "Instead, here, you sample **with replacements**. Let's see how it works now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc55508",
   "metadata": {
    "id": "6cc55508"
   },
   "source": [
    "#### Step 1: You are given a sample of $100$ returns, and you do not know the true distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b970e5",
   "metadata": {
    "id": "e4b970e5"
   },
   "outputs": [],
   "source": [
    "given_returns = np.random.multivariate_normal(mu, r, size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728f186",
   "metadata": {
    "id": "b728f186"
   },
   "source": [
    "#### Step 2: Estimate the optimal investment strategy by estimating $\\hat{\\alpha}$ from the given returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c8181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "705c8181",
    "outputId": "0b59a0d4-be68-4b0b-cd5c-ce68422afeea"
   },
   "outputs": [],
   "source": [
    "estimated_alpha = hat_alpha(given_returns)\n",
    "estimated_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88ec88",
   "metadata": {
    "id": "9d88ec88"
   },
   "source": [
    "#### Step 3: Observe the standard error associated with such an estimation technique by using bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4329e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ab4329e",
    "outputId": "0558800b-1038-43b3-f3f9-166dd9117878"
   },
   "outputs": [],
   "source": [
    "simulation = 1000#Same as before\n",
    "B = simulation\n",
    "samples = 100#Same\n",
    "estimations = np.zeros(simulation)#Same as before\n",
    "for sim in range(simulation):\n",
    "    generated_sample = given_returns[np.random.randint(given_returns.shape[0], size=samples), :]\n",
    "    estimations[sim] = hat_alpha(generated_sample)\n",
    "print(\"mean\", round(np.mean(estimations),3),\"min\",np.min(estimations), \"max\", np.max(estimations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba951c99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba951c99",
    "outputId": "8798fdf9-ec48-4327-ab63-b99977d7d3b1"
   },
   "outputs": [],
   "source": [
    "#Compute standard error\n",
    "bootstrap_error = np.sqrt( np.sum(np.square(estimations - np.mean(estimations))) /(B-1))\n",
    "np.round(bootstrap_error,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33608fee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33608fee",
    "outputId": "b31b15a1-1387-425e-dbf9-0ea51932d31d"
   },
   "outputs": [],
   "source": [
    "print(\"The estimation of the standard error from the simulations when we knew the distribution (which is very close to the truth due to the law of large numbers) was\", round(standard_error,3))\n",
    "print(\"While the bootstrap estimation of the standard error is\", round(bootstrap_error,3))\n",
    "print(\"Bootstrapping does not use any single information except for the given single 100-returns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe5beb",
   "metadata": {
    "id": "42fe5beb"
   },
   "source": [
    "### Question 6: When given a single sample of $100$ returns and estimate $\\hat{\\alpha}$, how can you obtain a confidence interval of the true $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f330bc",
   "metadata": {
    "id": "87f330bc"
   },
   "source": [
    "**Answer 6:** This answer is inspired by ```Professor Martin Haugh```'s lecture notes on ```resampling methods```.\n",
    "Let's review a $1-\\beta$-confidence interval (CI) on the true $\\alpha$. Fix any $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9463b7",
   "metadata": {
    "id": "6e9463b7"
   },
   "outputs": [],
   "source": [
    "beta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4047af4",
   "metadata": {
    "id": "a4047af4"
   },
   "source": [
    "Let $q_l, \\ q_u$ be the $\\beta/2$ lower and upper quantiles of the bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86eb7a4",
   "metadata": {
    "id": "d86eb7a4"
   },
   "outputs": [],
   "source": [
    "ql = np.quantile(estimations, beta/2)\n",
    "qu = np.quantile(estimations, 1- beta/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c6dc9",
   "metadata": {
    "id": "9a7c6dc9"
   },
   "source": [
    "Then, the fraction of $\\hat{\\alpha}_b$ satisfying $q_l \\leq \\hat{\\alpha}_b \\leq q_u$ out of all $b=1,\\ldots,B$ (where $B =1,000$ in this case) is $1-  \\beta$. Let's observe this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a9279",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "339a9279",
    "outputId": "21a99a3d-e78e-49a3-ea54-f1c655084cd2"
   },
   "outputs": [],
   "source": [
    "collect = 0\n",
    "for i in range(B):\n",
    "    if estimations[i] <= qu and estimations[i] >= ql:\n",
    "        collect += 1\n",
    "collect/B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ae1ad",
   "metadata": {
    "id": "1e6ae1ad"
   },
   "source": [
    "A naive approach is to claim $\\alpha$ lies in the range $[q_l, q_u]$ which is a $1-\\beta$ ($90\\%$ in this case) confidence interval. Hence in our case (recall true $\\alpha = 0.6$), the confidence interval is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c26ca3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78c26ca3",
    "outputId": "fbc57f95-a4bd-457b-c581-c82c51df443c"
   },
   "outputs": [],
   "source": [
    "np.array([ql, qu])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03590b71",
   "metadata": {
    "id": "03590b71"
   },
   "source": [
    "However, you can improve this. Recall that $\\bar{\\alpha}$ is the estimation by using the whole sample of 100 returns. It is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15181507",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15181507",
    "outputId": "4be06c99-eb42-42f3-b26c-a5aff3b49e85"
   },
   "outputs": [],
   "source": [
    "bar_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68594699",
   "metadata": {
    "id": "68594699"
   },
   "source": [
    "The estimations that satisfy $q_l \\leq \\hat{\\alpha}_b \\leq q_u$ also satisfy $\\bar{\\alpha} - q_u \\leq \\bar{\\alpha} - \\hat{\\alpha}_b \\leq \\bar{\\alpha} -q_l$. Hence, $\\bar{\\alpha} - q_u$ and $\\bar{\\alpha}- q_l$ are lower/upper $\\beta/2$ quantiles for $\\bar{\\alpha} - \\hat{\\alpha}_b$!\n",
    "\n",
    "So adding $\\bar{\\alpha}$ to this equation, you will obtain: $2\\bar{\\alpha} - q_u \\leq \\alpha \\leq 2\\bar{\\alpha}  - q_l$.\n",
    "\n",
    "Thus, a $(1 - \\beta)\\%$ CI of the true $\\alpha$ is $(2\\bar{\\alpha} - q_u, 2\\bar{\\alpha}  - q_l)$. In our case, a $90\\%$ CI is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d1fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "740d1fef",
    "outputId": "f586e14f-0eb8-44b1-b421-d8f40ca26ad9"
   },
   "outputs": [],
   "source": [
    "np.array([2*bar_alpha - qu, 2*bar_alpha - ql])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f10ac9",
   "metadata": {
    "id": "72f10ac9"
   },
   "source": [
    "Note that previously, you observed that the minimum bootstrap estimate of the $\\alpha$ was $0.35$ and the maximum was $0.85$, so you can observe how a $90\\%$ CI is more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb353c9",
   "metadata": {
    "id": "4bb353c9"
   },
   "source": [
    "### Answer this question: How would you modify the estimation of $\\alpha$, the simulation and the bootstrapping for obtaining CI, if you were told that $(X,Y)$ has a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzaTnajkotP_",
   "metadata": {
    "id": "tzaTnajkotP_"
   },
   "source": [
    "Hint: $$ \\alpha = \\frac{\\sigma_X^2 + \\sigma_Y^2 - 2 \\rho \\sigma_X \\sigma_Y}{\\sigma_Y^2 - \\rho \\sigma_X \\sigma_Y} $$\n",
    " Use the above notation of $\\alpha$, create the function and get the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v_UyMqtXosV6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_UyMqtXosV6",
    "outputId": "8048a7e1-54c4-4cd1-94d6-c41e63a36a06"
   },
   "outputs": [],
   "source": [
    "#Generate data\n",
    "\n",
    "mu = [0, 0]\n",
    "cov = [[1, 0.4],\n",
    "       [0.4, 1]]\n",
    "\n",
    "#Number of samples to generate\n",
    "n_samples = 1000\n",
    "\n",
    "#Generate bivariate normal data\n",
    "data = np.random.multivariate_normal(mean=mu, cov=cov, size=n_samples)\n",
    "\n",
    "#Split into X and Y components\n",
    "X = data[:, 0]\n",
    "Y = data[:, 1]\n",
    "\n",
    "print(\"Generated Data:\")\n",
    "print(\"X:\", X[:5])  # Print first 5 samples of X\n",
    "print(\"Y:\", Y[:5])  # Print first 5 samples of Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YCuDWHkOpZC5",
   "metadata": {
    "id": "YCuDWHkOpZC5"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Fit bivariate normal to data\n",
    "mu = np.mean(data, axis=0)\n",
    "cov = np.cov(data.T)\n",
    "n_bootstrap = 10000\n",
    "\n",
    "#Parametric bootstrap\n",
    "alpha_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    sample = multivariate_normal.rvs(mean=mu, cov=cov, size=n)\n",
    "    sigma_X = np.var(sample[:,0])\n",
    "    sigma_Y = np.var(sample[:,1])\n",
    "    rho = np.corrcoef(sample.T)[0,1]\n",
    "    alpha = (sigma_Y**2 - rho * np.sqrt(sigma_X * sigma_Y)) / (sigma_X + sigma_Y - 2 * rho * np.sqrt(sigma_X * sigma_Y))\n",
    "    alpha_bootstrap.append(alpha)\n",
    "\n",
    "CI = np.percentile(alpha_bootstrap, [2.5, 97.5])\n",
    "print(\"The confidence interval is given by \", CI)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
